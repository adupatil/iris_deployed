{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.pieriandata.com\"><img src=\"../Pierian_Data_Logo.PNG\"></a>\n",
    "<strong><center>Copyright by Pierian Data Inc.</center></strong> \n",
    "<strong><center>Created by Jose Marcial Portilla.</center></strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEPLOYMENT\n",
    "\n",
    "**Welcome to deployment section! In this section of the course, we will go through the entire deployment process, starting as if you had to create a servicable model from scratch, then deploy it for others to use, either through API or a web form.**\n",
    "\n",
    "# Data\n",
    "\n",
    "For this example we use the very common data set: [iris dataset](https://en.wikipedia.org/wiki/Iris_flower_data_set), which is about flowers. \n",
    "\n",
    "From Wikipedia:\n",
    "The Iris flower data set or Fisher's Iris data set is a multivariate data set introduced by the British statistician and biologist Ronald Fisher in his 1936 paper The use of multiple measurements in taxonomic problems as an example of linear discriminant analysis.[1] It is sometimes called Anderson's Iris data set because Edgar Anderson collected the data to quantify the morphologic variation of Iris flowers of three related species.[2] Two of the three species were collected in the Gasp√© Peninsula \"all from the same pasture, and picked on the same day and measured at the same time by the same person with the same apparatus\".[3]\n",
    "\n",
    "The data set consists of 50 samples from each of three species of Iris (Iris setosa, Iris virginica and Iris versicolor). Four features were measured from each sample: the length and the width of the sepals and petals, in centimeters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = pd.read_csv(\"../DATA/iris.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sepal_length', 'sepal_width', 'petal_length', 'petal_width',\n",
       "       'species'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.drop('species',axis=1)\n",
    "y = iris['species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris['species'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lots of ways to one hot encode\n",
    "# https://stackoverflow.com/questions/47573293/unable-to-transform-string-column-to-categorical-matrix-using-keras-and-sklearn\n",
    "# https://stackoverflow.com/questions/35107559/one-hot-encoding-of-string-categorical-features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "encoder = LabelBinarizer()\n",
    "y = encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X_train = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "\n",
    "### Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=4,activation='relu',input_shape=[4,]))\n",
    "\n",
    "# Last layer for multi-class classification of 3 species\n",
    "model.add(Dense(units=3,activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "4/4 [==============================] - 2s 217ms/step - loss: 1.1539 - accuracy: 0.3869 - val_loss: 1.0945 - val_accuracy: 0.5000\n",
      "Epoch 2/300\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.1162 - accuracy: 0.4365 - val_loss: 1.0887 - val_accuracy: 0.5000\n",
      "Epoch 3/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1.1230 - accuracy: 0.4588 - val_loss: 1.0831 - val_accuracy: 0.5000\n",
      "Epoch 4/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.1054 - accuracy: 0.4592 - val_loss: 1.0773 - val_accuracy: 0.5000\n",
      "Epoch 5/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1.1043 - accuracy: 0.4931 - val_loss: 1.0717 - val_accuracy: 0.5000\n",
      "Epoch 6/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1.1172 - accuracy: 0.4517 - val_loss: 1.0663 - val_accuracy: 0.5000\n",
      "Epoch 7/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1.1060 - accuracy: 0.4906 - val_loss: 1.0609 - val_accuracy: 0.5333\n",
      "Epoch 8/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1.0892 - accuracy: 0.5004 - val_loss: 1.0555 - val_accuracy: 0.5667\n",
      "Epoch 9/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1.0750 - accuracy: 0.5181 - val_loss: 1.0504 - val_accuracy: 0.5667\n",
      "Epoch 10/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1.0651 - accuracy: 0.5215 - val_loss: 1.0456 - val_accuracy: 0.5667\n",
      "Epoch 11/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1.0549 - accuracy: 0.5394 - val_loss: 1.0410 - val_accuracy: 0.5667\n",
      "Epoch 12/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.0478 - accuracy: 0.5740 - val_loss: 1.0362 - val_accuracy: 0.5667\n",
      "Epoch 13/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1.0423 - accuracy: 0.5504 - val_loss: 1.0313 - val_accuracy: 0.5667\n",
      "Epoch 14/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1.0473 - accuracy: 0.5683 - val_loss: 1.0267 - val_accuracy: 0.5667\n",
      "Epoch 15/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.0303 - accuracy: 0.5569 - val_loss: 1.0223 - val_accuracy: 0.6000\n",
      "Epoch 16/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1.0337 - accuracy: 0.5602 - val_loss: 1.0177 - val_accuracy: 0.6000\n",
      "Epoch 17/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1.0211 - accuracy: 0.5990 - val_loss: 1.0131 - val_accuracy: 0.6000\n",
      "Epoch 18/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1.0171 - accuracy: 0.5883 - val_loss: 1.0087 - val_accuracy: 0.5667\n",
      "Epoch 19/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.0100 - accuracy: 0.5998 - val_loss: 1.0042 - val_accuracy: 0.5667\n",
      "Epoch 20/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.9897 - accuracy: 0.6831 - val_loss: 0.9997 - val_accuracy: 0.5333\n",
      "Epoch 21/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.0009 - accuracy: 0.6367 - val_loss: 0.9953 - val_accuracy: 0.4667\n",
      "Epoch 22/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.9823 - accuracy: 0.6444 - val_loss: 0.9910 - val_accuracy: 0.4667\n",
      "Epoch 23/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.9846 - accuracy: 0.6094 - val_loss: 0.9868 - val_accuracy: 0.4667\n",
      "Epoch 24/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.9752 - accuracy: 0.6242 - val_loss: 0.9826 - val_accuracy: 0.4667\n",
      "Epoch 25/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.9696 - accuracy: 0.6244 - val_loss: 0.9784 - val_accuracy: 0.4667\n",
      "Epoch 26/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.9637 - accuracy: 0.6275 - val_loss: 0.9743 - val_accuracy: 0.5333\n",
      "Epoch 27/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.9594 - accuracy: 0.6550 - val_loss: 0.9701 - val_accuracy: 0.6000\n",
      "Epoch 28/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.9560 - accuracy: 0.6815 - val_loss: 0.9660 - val_accuracy: 0.6000\n",
      "Epoch 29/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.9445 - accuracy: 0.7085 - val_loss: 0.9618 - val_accuracy: 0.6000\n",
      "Epoch 30/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.9453 - accuracy: 0.6900 - val_loss: 0.9576 - val_accuracy: 0.6333\n",
      "Epoch 31/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.9287 - accuracy: 0.7015 - val_loss: 0.9536 - val_accuracy: 0.6333\n",
      "Epoch 32/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.9330 - accuracy: 0.7246 - val_loss: 0.9492 - val_accuracy: 0.6333\n",
      "Epoch 33/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.9338 - accuracy: 0.6871 - val_loss: 0.9451 - val_accuracy: 0.6000\n",
      "Epoch 34/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.9194 - accuracy: 0.7017 - val_loss: 0.9410 - val_accuracy: 0.6000\n",
      "Epoch 35/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.9110 - accuracy: 0.6992 - val_loss: 0.9371 - val_accuracy: 0.5667\n",
      "Epoch 36/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.9119 - accuracy: 0.6804 - val_loss: 0.9329 - val_accuracy: 0.5667\n",
      "Epoch 37/300\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.9035 - accuracy: 0.6954 - val_loss: 0.9289 - val_accuracy: 0.6000\n",
      "Epoch 38/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.9051 - accuracy: 0.6671 - val_loss: 0.9248 - val_accuracy: 0.6000\n",
      "Epoch 39/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8935 - accuracy: 0.6950 - val_loss: 0.9208 - val_accuracy: 0.6000\n",
      "Epoch 40/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.9000 - accuracy: 0.6398 - val_loss: 0.9166 - val_accuracy: 0.6000\n",
      "Epoch 41/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.8890 - accuracy: 0.6638 - val_loss: 0.9127 - val_accuracy: 0.6000\n",
      "Epoch 42/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.8815 - accuracy: 0.6729 - val_loss: 0.9087 - val_accuracy: 0.5667\n",
      "Epoch 43/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8723 - accuracy: 0.6654 - val_loss: 0.9046 - val_accuracy: 0.5667\n",
      "Epoch 44/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8792 - accuracy: 0.6267 - val_loss: 0.9005 - val_accuracy: 0.5667\n",
      "Epoch 45/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8625 - accuracy: 0.6821 - val_loss: 0.8967 - val_accuracy: 0.5667\n",
      "Epoch 46/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.8637 - accuracy: 0.6898 - val_loss: 0.8926 - val_accuracy: 0.5667\n",
      "Epoch 47/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.8567 - accuracy: 0.6712 - val_loss: 0.8884 - val_accuracy: 0.5667\n",
      "Epoch 48/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.8541 - accuracy: 0.6702 - val_loss: 0.8844 - val_accuracy: 0.5667\n",
      "Epoch 49/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8517 - accuracy: 0.6954 - val_loss: 0.8803 - val_accuracy: 0.5667\n",
      "Epoch 50/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8429 - accuracy: 0.6956 - val_loss: 0.8765 - val_accuracy: 0.5667\n",
      "Epoch 51/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8535 - accuracy: 0.6477 - val_loss: 0.8726 - val_accuracy: 0.5667\n",
      "Epoch 52/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8373 - accuracy: 0.6821 - val_loss: 0.8687 - val_accuracy: 0.5667\n",
      "Epoch 53/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8289 - accuracy: 0.7040 - val_loss: 0.8651 - val_accuracy: 0.5667\n",
      "Epoch 54/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.8276 - accuracy: 0.6785 - val_loss: 0.8616 - val_accuracy: 0.5667\n",
      "Epoch 55/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.8167 - accuracy: 0.6921 - val_loss: 0.8582 - val_accuracy: 0.6000\n",
      "Epoch 56/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.8226 - accuracy: 0.6585 - val_loss: 0.8548 - val_accuracy: 0.6000\n",
      "Epoch 57/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.8176 - accuracy: 0.6398 - val_loss: 0.8514 - val_accuracy: 0.6000\n",
      "Epoch 58/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7981 - accuracy: 0.7096 - val_loss: 0.8483 - val_accuracy: 0.6000\n",
      "Epoch 59/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7998 - accuracy: 0.6783 - val_loss: 0.8452 - val_accuracy: 0.6000\n",
      "Epoch 60/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8035 - accuracy: 0.7015 - val_loss: 0.8420 - val_accuracy: 0.6000\n",
      "Epoch 61/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.8027 - accuracy: 0.6723 - val_loss: 0.8387 - val_accuracy: 0.6000\n",
      "Epoch 62/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7964 - accuracy: 0.6858 - val_loss: 0.8354 - val_accuracy: 0.6000\n",
      "Epoch 63/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7900 - accuracy: 0.6796 - val_loss: 0.8323 - val_accuracy: 0.6000\n",
      "Epoch 64/300\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.7735 - accuracy: 0.7192 - val_loss: 0.8291 - val_accuracy: 0.6000\n",
      "Epoch 65/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7837 - accuracy: 0.6858 - val_loss: 0.8258 - val_accuracy: 0.6000\n",
      "Epoch 66/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7843 - accuracy: 0.6619 - val_loss: 0.8224 - val_accuracy: 0.6000\n",
      "Epoch 67/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7741 - accuracy: 0.6848 - val_loss: 0.8193 - val_accuracy: 0.6000\n",
      "Epoch 68/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7631 - accuracy: 0.6942 - val_loss: 0.8161 - val_accuracy: 0.6000\n",
      "Epoch 69/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7549 - accuracy: 0.6900 - val_loss: 0.8131 - val_accuracy: 0.6000\n",
      "Epoch 70/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7608 - accuracy: 0.6837 - val_loss: 0.8101 - val_accuracy: 0.6000\n",
      "Epoch 71/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7578 - accuracy: 0.6931 - val_loss: 0.8071 - val_accuracy: 0.6000\n",
      "Epoch 72/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7578 - accuracy: 0.6827 - val_loss: 0.8040 - val_accuracy: 0.5667\n",
      "Epoch 73/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7541 - accuracy: 0.6858 - val_loss: 0.8011 - val_accuracy: 0.5667\n",
      "Epoch 74/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7514 - accuracy: 0.6775 - val_loss: 0.7980 - val_accuracy: 0.5667\n",
      "Epoch 75/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7536 - accuracy: 0.6494 - val_loss: 0.7946 - val_accuracy: 0.5667\n",
      "Epoch 76/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7327 - accuracy: 0.6973 - val_loss: 0.7916 - val_accuracy: 0.5667\n",
      "Epoch 77/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7236 - accuracy: 0.6962 - val_loss: 0.7884 - val_accuracy: 0.5667\n",
      "Epoch 78/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7298 - accuracy: 0.7035 - val_loss: 0.7856 - val_accuracy: 0.5667\n",
      "Epoch 79/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7264 - accuracy: 0.7046 - val_loss: 0.7826 - val_accuracy: 0.5667\n",
      "Epoch 80/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7194 - accuracy: 0.7004 - val_loss: 0.7794 - val_accuracy: 0.5667\n",
      "Epoch 81/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7064 - accuracy: 0.7337 - val_loss: 0.7766 - val_accuracy: 0.5667\n",
      "Epoch 82/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7435 - accuracy: 0.6275 - val_loss: 0.7731 - val_accuracy: 0.5667\n",
      "Epoch 83/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7190 - accuracy: 0.6931 - val_loss: 0.7703 - val_accuracy: 0.5667\n",
      "Epoch 84/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7039 - accuracy: 0.6962 - val_loss: 0.7671 - val_accuracy: 0.5667\n",
      "Epoch 85/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7077 - accuracy: 0.7046 - val_loss: 0.7642 - val_accuracy: 0.5667\n",
      "Epoch 86/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7017 - accuracy: 0.6973 - val_loss: 0.7612 - val_accuracy: 0.5667\n",
      "Epoch 87/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7074 - accuracy: 0.6858 - val_loss: 0.7583 - val_accuracy: 0.5667\n",
      "Epoch 88/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7045 - accuracy: 0.6848 - val_loss: 0.7556 - val_accuracy: 0.5667\n",
      "Epoch 89/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7025 - accuracy: 0.6754 - val_loss: 0.7528 - val_accuracy: 0.5667\n",
      "Epoch 90/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6990 - accuracy: 0.6785 - val_loss: 0.7496 - val_accuracy: 0.5667\n",
      "Epoch 91/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6863 - accuracy: 0.6952 - val_loss: 0.7468 - val_accuracy: 0.6000\n",
      "Epoch 92/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7010 - accuracy: 0.6567 - val_loss: 0.7441 - val_accuracy: 0.6000\n",
      "Epoch 93/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6946 - accuracy: 0.6629 - val_loss: 0.7412 - val_accuracy: 0.6000\n",
      "Epoch 94/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6995 - accuracy: 0.6431 - val_loss: 0.7384 - val_accuracy: 0.6000\n",
      "Epoch 95/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6703 - accuracy: 0.7140 - val_loss: 0.7359 - val_accuracy: 0.6000\n",
      "Epoch 96/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6636 - accuracy: 0.7056 - val_loss: 0.7330 - val_accuracy: 0.6000\n",
      "Epoch 97/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6784 - accuracy: 0.6900 - val_loss: 0.7303 - val_accuracy: 0.6000\n",
      "Epoch 98/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6605 - accuracy: 0.6952 - val_loss: 0.7274 - val_accuracy: 0.6000\n",
      "Epoch 99/300\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.6658 - accuracy: 0.6754 - val_loss: 0.7246 - val_accuracy: 0.6000\n",
      "Epoch 100/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6669 - accuracy: 0.6806 - val_loss: 0.7221 - val_accuracy: 0.6000\n",
      "Epoch 101/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6588 - accuracy: 0.6869 - val_loss: 0.7194 - val_accuracy: 0.6000\n",
      "Epoch 102/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6532 - accuracy: 0.7087 - val_loss: 0.7170 - val_accuracy: 0.6000\n",
      "Epoch 103/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6446 - accuracy: 0.7140 - val_loss: 0.7144 - val_accuracy: 0.6000\n",
      "Epoch 104/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.6559 - accuracy: 0.6712 - val_loss: 0.7115 - val_accuracy: 0.6000\n",
      "Epoch 105/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6591 - accuracy: 0.6692 - val_loss: 0.7088 - val_accuracy: 0.6000\n",
      "Epoch 106/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6593 - accuracy: 0.6546 - val_loss: 0.7059 - val_accuracy: 0.6000\n",
      "Epoch 107/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6382 - accuracy: 0.6952 - val_loss: 0.7031 - val_accuracy: 0.6000\n",
      "Epoch 108/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6281 - accuracy: 0.7129 - val_loss: 0.7006 - val_accuracy: 0.6000\n",
      "Epoch 109/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6314 - accuracy: 0.6942 - val_loss: 0.6980 - val_accuracy: 0.6000\n",
      "Epoch 110/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6464 - accuracy: 0.6442 - val_loss: 0.6951 - val_accuracy: 0.6000\n",
      "Epoch 111/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.6161 - accuracy: 0.7067 - val_loss: 0.6928 - val_accuracy: 0.6000\n",
      "Epoch 112/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6364 - accuracy: 0.6744 - val_loss: 0.6901 - val_accuracy: 0.6000\n",
      "Epoch 113/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6048 - accuracy: 0.7317 - val_loss: 0.6877 - val_accuracy: 0.6000\n",
      "Epoch 114/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6447 - accuracy: 0.6421 - val_loss: 0.6848 - val_accuracy: 0.6000\n",
      "Epoch 115/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6305 - accuracy: 0.6723 - val_loss: 0.6823 - val_accuracy: 0.6000\n",
      "Epoch 116/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6373 - accuracy: 0.6577 - val_loss: 0.6797 - val_accuracy: 0.6000\n",
      "Epoch 117/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6259 - accuracy: 0.6671 - val_loss: 0.6772 - val_accuracy: 0.6000\n",
      "Epoch 118/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6211 - accuracy: 0.6775 - val_loss: 0.6749 - val_accuracy: 0.6000\n",
      "Epoch 119/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5930 - accuracy: 0.7202 - val_loss: 0.6726 - val_accuracy: 0.6000\n",
      "Epoch 120/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5991 - accuracy: 0.6973 - val_loss: 0.6702 - val_accuracy: 0.6000\n",
      "Epoch 121/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6083 - accuracy: 0.6765 - val_loss: 0.6676 - val_accuracy: 0.6000\n",
      "Epoch 122/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5903 - accuracy: 0.7067 - val_loss: 0.6653 - val_accuracy: 0.6000\n",
      "Epoch 123/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5964 - accuracy: 0.6962 - val_loss: 0.6627 - val_accuracy: 0.6000\n",
      "Epoch 124/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6159 - accuracy: 0.6640 - val_loss: 0.6602 - val_accuracy: 0.6000\n",
      "Epoch 125/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5950 - accuracy: 0.6900 - val_loss: 0.6579 - val_accuracy: 0.6000\n",
      "Epoch 126/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5920 - accuracy: 0.6962 - val_loss: 0.6554 - val_accuracy: 0.6000\n",
      "Epoch 127/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.6112 - accuracy: 0.6608 - val_loss: 0.6530 - val_accuracy: 0.6000\n",
      "Epoch 128/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5734 - accuracy: 0.7160 - val_loss: 0.6507 - val_accuracy: 0.6000\n",
      "Epoch 129/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5972 - accuracy: 0.6610 - val_loss: 0.6480 - val_accuracy: 0.6000\n",
      "Epoch 130/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5933 - accuracy: 0.6892 - val_loss: 0.6457 - val_accuracy: 0.6000\n",
      "Epoch 131/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5737 - accuracy: 0.7121 - val_loss: 0.6433 - val_accuracy: 0.6000\n",
      "Epoch 132/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5860 - accuracy: 0.6913 - val_loss: 0.6408 - val_accuracy: 0.6000\n",
      "Epoch 133/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5836 - accuracy: 0.6975 - val_loss: 0.6384 - val_accuracy: 0.6000\n",
      "Epoch 134/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5559 - accuracy: 0.7329 - val_loss: 0.6363 - val_accuracy: 0.6000\n",
      "Epoch 135/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5568 - accuracy: 0.6996 - val_loss: 0.6337 - val_accuracy: 0.6000\n",
      "Epoch 136/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5640 - accuracy: 0.7142 - val_loss: 0.6316 - val_accuracy: 0.6000\n",
      "Epoch 137/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5870 - accuracy: 0.6527 - val_loss: 0.6291 - val_accuracy: 0.6000\n",
      "Epoch 138/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5761 - accuracy: 0.6954 - val_loss: 0.6271 - val_accuracy: 0.6000\n",
      "Epoch 139/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5615 - accuracy: 0.6985 - val_loss: 0.6251 - val_accuracy: 0.6000\n",
      "Epoch 140/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5699 - accuracy: 0.6735 - val_loss: 0.6230 - val_accuracy: 0.6000\n",
      "Epoch 141/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5687 - accuracy: 0.6840 - val_loss: 0.6210 - val_accuracy: 0.6000\n",
      "Epoch 142/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5771 - accuracy: 0.6735 - val_loss: 0.6189 - val_accuracy: 0.6000\n",
      "Epoch 143/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5397 - accuracy: 0.7131 - val_loss: 0.6167 - val_accuracy: 0.6000\n",
      "Epoch 144/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5618 - accuracy: 0.6852 - val_loss: 0.6144 - val_accuracy: 0.6000\n",
      "Epoch 145/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5620 - accuracy: 0.6665 - val_loss: 0.6122 - val_accuracy: 0.6000\n",
      "Epoch 146/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5473 - accuracy: 0.7123 - val_loss: 0.6105 - val_accuracy: 0.6000\n",
      "Epoch 147/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5517 - accuracy: 0.6904 - val_loss: 0.6085 - val_accuracy: 0.6000\n",
      "Epoch 148/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5517 - accuracy: 0.6800 - val_loss: 0.6064 - val_accuracy: 0.6000\n",
      "Epoch 149/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5568 - accuracy: 0.6665 - val_loss: 0.6041 - val_accuracy: 0.6000\n",
      "Epoch 150/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5491 - accuracy: 0.6927 - val_loss: 0.6022 - val_accuracy: 0.6000\n",
      "Epoch 151/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5602 - accuracy: 0.6771 - val_loss: 0.6002 - val_accuracy: 0.6000\n",
      "Epoch 152/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5408 - accuracy: 0.6896 - val_loss: 0.5981 - val_accuracy: 0.6000\n",
      "Epoch 153/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5259 - accuracy: 0.7146 - val_loss: 0.5962 - val_accuracy: 0.6000\n",
      "Epoch 154/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.5501 - accuracy: 0.6979 - val_loss: 0.5944 - val_accuracy: 0.6000\n",
      "Epoch 155/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5373 - accuracy: 0.7104 - val_loss: 0.5923 - val_accuracy: 0.6000\n",
      "Epoch 156/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5420 - accuracy: 0.6865 - val_loss: 0.5901 - val_accuracy: 0.6000\n",
      "Epoch 157/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5470 - accuracy: 0.6960 - val_loss: 0.5880 - val_accuracy: 0.6000\n",
      "Epoch 158/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5195 - accuracy: 0.7244 - val_loss: 0.5860 - val_accuracy: 0.6333\n",
      "Epoch 159/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5275 - accuracy: 0.7306 - val_loss: 0.5841 - val_accuracy: 0.6000\n",
      "Epoch 160/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5178 - accuracy: 0.7358 - val_loss: 0.5823 - val_accuracy: 0.6000\n",
      "Epoch 161/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5399 - accuracy: 0.6921 - val_loss: 0.5800 - val_accuracy: 0.6333\n",
      "Epoch 162/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.5362 - accuracy: 0.6713 - val_loss: 0.5780 - val_accuracy: 0.6333\n",
      "Epoch 163/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5188 - accuracy: 0.7390 - val_loss: 0.5765 - val_accuracy: 0.6333\n",
      "Epoch 164/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.5218 - accuracy: 0.7233 - val_loss: 0.5748 - val_accuracy: 0.6333\n",
      "Epoch 165/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5182 - accuracy: 0.7077 - val_loss: 0.5728 - val_accuracy: 0.6667\n",
      "Epoch 166/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5008 - accuracy: 0.7265 - val_loss: 0.5711 - val_accuracy: 0.6667\n",
      "Epoch 167/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5144 - accuracy: 0.7308 - val_loss: 0.5692 - val_accuracy: 0.6667\n",
      "Epoch 168/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4997 - accuracy: 0.7506 - val_loss: 0.5675 - val_accuracy: 0.6667\n",
      "Epoch 169/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5134 - accuracy: 0.7329 - val_loss: 0.5655 - val_accuracy: 0.6667\n",
      "Epoch 170/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5034 - accuracy: 0.7183 - val_loss: 0.5634 - val_accuracy: 0.6667\n",
      "Epoch 171/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4930 - accuracy: 0.7279 - val_loss: 0.5613 - val_accuracy: 0.7333\n",
      "Epoch 172/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5011 - accuracy: 0.7383 - val_loss: 0.5594 - val_accuracy: 0.7333\n",
      "Epoch 173/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5110 - accuracy: 0.7490 - val_loss: 0.5576 - val_accuracy: 0.7333\n",
      "Epoch 174/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4949 - accuracy: 0.7615 - val_loss: 0.5558 - val_accuracy: 0.7667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4972 - accuracy: 0.7292 - val_loss: 0.5539 - val_accuracy: 0.7667\n",
      "Epoch 176/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4851 - accuracy: 0.7656 - val_loss: 0.5522 - val_accuracy: 0.8000\n",
      "Epoch 177/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4956 - accuracy: 0.7785 - val_loss: 0.5506 - val_accuracy: 0.8000\n",
      "Epoch 178/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4910 - accuracy: 0.7723 - val_loss: 0.5486 - val_accuracy: 0.8000\n",
      "Epoch 179/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5067 - accuracy: 0.7631 - val_loss: 0.5465 - val_accuracy: 0.8000\n",
      "Epoch 180/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4810 - accuracy: 0.7902 - val_loss: 0.5448 - val_accuracy: 0.8000\n",
      "Epoch 181/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4731 - accuracy: 0.8029 - val_loss: 0.5431 - val_accuracy: 0.8000\n",
      "Epoch 182/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4735 - accuracy: 0.7873 - val_loss: 0.5411 - val_accuracy: 0.8333\n",
      "Epoch 183/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4909 - accuracy: 0.7719 - val_loss: 0.5392 - val_accuracy: 0.8333\n",
      "Epoch 184/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4865 - accuracy: 0.8106 - val_loss: 0.5375 - val_accuracy: 0.8333\n",
      "Epoch 185/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5098 - accuracy: 0.7679 - val_loss: 0.5356 - val_accuracy: 0.8333\n",
      "Epoch 186/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4783 - accuracy: 0.7856 - val_loss: 0.5337 - val_accuracy: 0.8333\n",
      "Epoch 187/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4633 - accuracy: 0.8127 - val_loss: 0.5327 - val_accuracy: 0.8333\n",
      "Epoch 188/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4744 - accuracy: 0.8252 - val_loss: 0.5314 - val_accuracy: 0.8333\n",
      "Epoch 189/300\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.5007 - accuracy: 0.7752 - val_loss: 0.5294 - val_accuracy: 0.8333\n",
      "Epoch 190/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4776 - accuracy: 0.7877 - val_loss: 0.5275 - val_accuracy: 0.8333\n",
      "Epoch 191/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4781 - accuracy: 0.8002 - val_loss: 0.5259 - val_accuracy: 0.8333\n",
      "Epoch 192/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4679 - accuracy: 0.7960 - val_loss: 0.5243 - val_accuracy: 0.8667\n",
      "Epoch 193/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4592 - accuracy: 0.8033 - val_loss: 0.5228 - val_accuracy: 0.8667\n",
      "Epoch 194/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4729 - accuracy: 0.7815 - val_loss: 0.5212 - val_accuracy: 0.8667\n",
      "Epoch 195/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4763 - accuracy: 0.7867 - val_loss: 0.5198 - val_accuracy: 0.8667\n",
      "Epoch 196/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4456 - accuracy: 0.8013 - val_loss: 0.5182 - val_accuracy: 0.8667\n",
      "Epoch 197/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4644 - accuracy: 0.7940 - val_loss: 0.5168 - val_accuracy: 0.8667\n",
      "Epoch 198/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4275 - accuracy: 0.8221 - val_loss: 0.5153 - val_accuracy: 0.8667\n",
      "Epoch 199/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4806 - accuracy: 0.7690 - val_loss: 0.5133 - val_accuracy: 0.8667\n",
      "Epoch 200/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4413 - accuracy: 0.8223 - val_loss: 0.5119 - val_accuracy: 0.8667\n",
      "Epoch 201/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4602 - accuracy: 0.8192 - val_loss: 0.5101 - val_accuracy: 0.9000\n",
      "Epoch 202/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4523 - accuracy: 0.8350 - val_loss: 0.5083 - val_accuracy: 0.9000\n",
      "Epoch 203/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4305 - accuracy: 0.8183 - val_loss: 0.5066 - val_accuracy: 0.9000\n",
      "Epoch 204/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4377 - accuracy: 0.8246 - val_loss: 0.5049 - val_accuracy: 0.9000\n",
      "Epoch 205/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4696 - accuracy: 0.7944 - val_loss: 0.5030 - val_accuracy: 0.9000\n",
      "Epoch 206/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4575 - accuracy: 0.7881 - val_loss: 0.5011 - val_accuracy: 0.9000\n",
      "Epoch 207/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4635 - accuracy: 0.8163 - val_loss: 0.4995 - val_accuracy: 0.9000\n",
      "Epoch 208/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4687 - accuracy: 0.7923 - val_loss: 0.4977 - val_accuracy: 0.9000\n",
      "Epoch 209/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4462 - accuracy: 0.8100 - val_loss: 0.4963 - val_accuracy: 0.9000\n",
      "Epoch 210/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4322 - accuracy: 0.8340 - val_loss: 0.4952 - val_accuracy: 0.9000\n",
      "Epoch 211/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4421 - accuracy: 0.8225 - val_loss: 0.4938 - val_accuracy: 0.9000\n",
      "Epoch 212/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4441 - accuracy: 0.8027 - val_loss: 0.4925 - val_accuracy: 0.9000\n",
      "Epoch 213/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4661 - accuracy: 0.8173 - val_loss: 0.4910 - val_accuracy: 0.9000\n",
      "Epoch 214/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4311 - accuracy: 0.8246 - val_loss: 0.4896 - val_accuracy: 0.9333\n",
      "Epoch 215/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4416 - accuracy: 0.8144 - val_loss: 0.4884 - val_accuracy: 0.9333\n",
      "Epoch 216/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4224 - accuracy: 0.8235 - val_loss: 0.4872 - val_accuracy: 0.9333\n",
      "Epoch 217/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4398 - accuracy: 0.8027 - val_loss: 0.4857 - val_accuracy: 0.9333\n",
      "Epoch 218/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4276 - accuracy: 0.8175 - val_loss: 0.4843 - val_accuracy: 0.9333\n",
      "Epoch 219/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4370 - accuracy: 0.8133 - val_loss: 0.4827 - val_accuracy: 0.9333\n",
      "Epoch 220/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4293 - accuracy: 0.8292 - val_loss: 0.4812 - val_accuracy: 0.9333\n",
      "Epoch 221/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4228 - accuracy: 0.8302 - val_loss: 0.4794 - val_accuracy: 0.9333\n",
      "Epoch 222/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4197 - accuracy: 0.8523 - val_loss: 0.4782 - val_accuracy: 0.9333\n",
      "Epoch 223/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3929 - accuracy: 0.8523 - val_loss: 0.4768 - val_accuracy: 0.9333\n",
      "Epoch 224/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.4441 - accuracy: 0.8442 - val_loss: 0.4753 - val_accuracy: 0.9333\n",
      "Epoch 225/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4133 - accuracy: 0.8608 - val_loss: 0.4739 - val_accuracy: 0.9333\n",
      "Epoch 226/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4102 - accuracy: 0.8650 - val_loss: 0.4724 - val_accuracy: 0.9333\n",
      "Epoch 227/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4434 - accuracy: 0.8348 - val_loss: 0.4710 - val_accuracy: 0.9333\n",
      "Epoch 228/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4268 - accuracy: 0.8579 - val_loss: 0.4697 - val_accuracy: 0.9333\n",
      "Epoch 229/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4064 - accuracy: 0.8746 - val_loss: 0.4685 - val_accuracy: 0.9333\n",
      "Epoch 230/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4394 - accuracy: 0.8538 - val_loss: 0.4669 - val_accuracy: 0.9333\n",
      "Epoch 231/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4156 - accuracy: 0.8360 - val_loss: 0.4654 - val_accuracy: 0.9333\n",
      "Epoch 232/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4112 - accuracy: 0.8752 - val_loss: 0.4638 - val_accuracy: 0.9333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 233/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4233 - accuracy: 0.9077 - val_loss: 0.4624 - val_accuracy: 0.9333\n",
      "Epoch 234/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4277 - accuracy: 0.8660 - val_loss: 0.4610 - val_accuracy: 0.9667\n",
      "Epoch 235/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3926 - accuracy: 0.9233 - val_loss: 0.4600 - val_accuracy: 0.9667\n",
      "Epoch 236/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4215 - accuracy: 0.8679 - val_loss: 0.4587 - val_accuracy: 0.9667\n",
      "Epoch 237/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4204 - accuracy: 0.8877 - val_loss: 0.4572 - val_accuracy: 0.9667\n",
      "Epoch 238/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3992 - accuracy: 0.9002 - val_loss: 0.4562 - val_accuracy: 0.9667\n",
      "Epoch 239/300\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3964 - accuracy: 0.90 - 0s 13ms/step - loss: 0.3993 - accuracy: 0.8960 - val_loss: 0.4552 - val_accuracy: 0.9667\n",
      "Epoch 240/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3917 - accuracy: 0.8604 - val_loss: 0.4539 - val_accuracy: 0.9667\n",
      "Epoch 241/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4098 - accuracy: 0.8929 - val_loss: 0.4525 - val_accuracy: 0.9667\n",
      "Epoch 242/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3957 - accuracy: 0.8731 - val_loss: 0.4513 - val_accuracy: 0.9667\n",
      "Epoch 243/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4007 - accuracy: 0.8794 - val_loss: 0.4499 - val_accuracy: 0.9667\n",
      "Epoch 244/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4009 - accuracy: 0.8900 - val_loss: 0.4484 - val_accuracy: 0.9667\n",
      "Epoch 245/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3992 - accuracy: 0.8944 - val_loss: 0.4472 - val_accuracy: 0.9667\n",
      "Epoch 246/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4146 - accuracy: 0.8767 - val_loss: 0.4457 - val_accuracy: 0.9667\n",
      "Epoch 247/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3960 - accuracy: 0.9267 - val_loss: 0.4444 - val_accuracy: 0.9667\n",
      "Epoch 248/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3889 - accuracy: 0.9021 - val_loss: 0.4430 - val_accuracy: 0.9667\n",
      "Epoch 249/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3996 - accuracy: 0.9229 - val_loss: 0.4416 - val_accuracy: 0.9667\n",
      "Epoch 250/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3799 - accuracy: 0.9135 - val_loss: 0.4404 - val_accuracy: 0.9667\n",
      "Epoch 251/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3986 - accuracy: 0.9135 - val_loss: 0.4390 - val_accuracy: 0.9667\n",
      "Epoch 252/300\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.3686 - accuracy: 0.9375 - val_loss: 0.4382 - val_accuracy: 0.9667\n",
      "Epoch 253/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3873 - accuracy: 0.9042 - val_loss: 0.4367 - val_accuracy: 0.9667\n",
      "Epoch 254/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4098 - accuracy: 0.9085 - val_loss: 0.4350 - val_accuracy: 0.9667\n",
      "Epoch 255/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3767 - accuracy: 0.9481 - val_loss: 0.4338 - val_accuracy: 0.9667\n",
      "Epoch 256/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3772 - accuracy: 0.9440 - val_loss: 0.4325 - val_accuracy: 0.9667\n",
      "Epoch 257/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3759 - accuracy: 0.9335 - val_loss: 0.4310 - val_accuracy: 0.9667\n",
      "Epoch 258/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3985 - accuracy: 0.9294 - val_loss: 0.4295 - val_accuracy: 0.9667\n",
      "Epoch 259/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3950 - accuracy: 0.9033 - val_loss: 0.4280 - val_accuracy: 0.9667\n",
      "Epoch 260/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3690 - accuracy: 0.9381 - val_loss: 0.4269 - val_accuracy: 0.9667\n",
      "Epoch 261/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3725 - accuracy: 0.9388 - val_loss: 0.4261 - val_accuracy: 0.9667\n",
      "Epoch 262/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3830 - accuracy: 0.9304 - val_loss: 0.4250 - val_accuracy: 0.9667\n",
      "Epoch 263/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3836 - accuracy: 0.9075 - val_loss: 0.4239 - val_accuracy: 0.9667\n",
      "Epoch 264/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3942 - accuracy: 0.9346 - val_loss: 0.4231 - val_accuracy: 0.9667\n",
      "Epoch 265/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3758 - accuracy: 0.9210 - val_loss: 0.4219 - val_accuracy: 0.9667\n",
      "Epoch 266/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3815 - accuracy: 0.9065 - val_loss: 0.4206 - val_accuracy: 0.9667\n",
      "Epoch 267/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3887 - accuracy: 0.9231 - val_loss: 0.4195 - val_accuracy: 0.9667\n",
      "Epoch 268/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3714 - accuracy: 0.9273 - val_loss: 0.4185 - val_accuracy: 0.9667\n",
      "Epoch 269/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3867 - accuracy: 0.9106 - val_loss: 0.4171 - val_accuracy: 0.9667\n",
      "Epoch 270/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3796 - accuracy: 0.9360 - val_loss: 0.4161 - val_accuracy: 0.9667\n",
      "Epoch 271/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3755 - accuracy: 0.9340 - val_loss: 0.4150 - val_accuracy: 0.9667\n",
      "Epoch 272/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3765 - accuracy: 0.9444 - val_loss: 0.4138 - val_accuracy: 0.9667\n",
      "Epoch 273/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3789 - accuracy: 0.9456 - val_loss: 0.4127 - val_accuracy: 0.9667\n",
      "Epoch 274/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3744 - accuracy: 0.9425 - val_loss: 0.4114 - val_accuracy: 0.9667\n",
      "Epoch 275/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3545 - accuracy: 0.9621 - val_loss: 0.4107 - val_accuracy: 0.9667\n",
      "Epoch 276/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3773 - accuracy: 0.9602 - val_loss: 0.4095 - val_accuracy: 0.9667\n",
      "Epoch 277/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3667 - accuracy: 0.9469 - val_loss: 0.4082 - val_accuracy: 0.9667\n",
      "Epoch 278/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3621 - accuracy: 0.9594 - val_loss: 0.4070 - val_accuracy: 0.9667\n",
      "Epoch 279/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3503 - accuracy: 0.9719 - val_loss: 0.4060 - val_accuracy: 0.9667\n",
      "Epoch 280/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3693 - accuracy: 0.9542 - val_loss: 0.4048 - val_accuracy: 0.9667\n",
      "Epoch 281/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3522 - accuracy: 0.9615 - val_loss: 0.4035 - val_accuracy: 0.9667\n",
      "Epoch 282/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3638 - accuracy: 0.9687 - val_loss: 0.4022 - val_accuracy: 0.9667\n",
      "Epoch 283/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3649 - accuracy: 0.9565 - val_loss: 0.4007 - val_accuracy: 0.9667\n",
      "Epoch 284/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3484 - accuracy: 0.9658 - val_loss: 0.3994 - val_accuracy: 0.9667\n",
      "Epoch 285/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3719 - accuracy: 0.9565 - val_loss: 0.3987 - val_accuracy: 0.9667\n",
      "Epoch 286/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3448 - accuracy: 0.9762 - val_loss: 0.3976 - val_accuracy: 0.9667\n",
      "Epoch 287/300\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.3310 - accuracy: 0.9752 - val_loss: 0.3966 - val_accuracy: 0.9667\n",
      "Epoch 288/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3704 - accuracy: 0.9679 - val_loss: 0.3954 - val_accuracy: 0.9667\n",
      "Epoch 289/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3493 - accuracy: 0.9815 - val_loss: 0.3942 - val_accuracy: 0.9667\n",
      "Epoch 290/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3756 - accuracy: 0.9617 - val_loss: 0.3929 - val_accuracy: 0.9667\n",
      "Epoch 291/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3554 - accuracy: 0.9690 - val_loss: 0.3915 - val_accuracy: 0.9667\n",
      "Epoch 292/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3525 - accuracy: 0.9700 - val_loss: 0.3900 - val_accuracy: 0.9667\n",
      "Epoch 293/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3711 - accuracy: 0.9502 - val_loss: 0.3888 - val_accuracy: 0.9667\n",
      "Epoch 294/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3433 - accuracy: 0.9721 - val_loss: 0.3876 - val_accuracy: 0.9667\n",
      "Epoch 295/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3403 - accuracy: 0.9617 - val_loss: 0.3869 - val_accuracy: 0.9667\n",
      "Epoch 296/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3370 - accuracy: 0.9742 - val_loss: 0.3858 - val_accuracy: 0.9667\n",
      "Epoch 297/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3504 - accuracy: 0.9596 - val_loss: 0.3848 - val_accuracy: 0.9667\n",
      "Epoch 298/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3353 - accuracy: 0.9742 - val_loss: 0.3837 - val_accuracy: 0.9667\n",
      "Epoch 299/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3425 - accuracy: 0.9627 - val_loss: 0.3827 - val_accuracy: 0.9667\n",
      "Epoch 300/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3458 - accuracy: 0.9585 - val_loss: 0.3817 - val_accuracy: 0.9667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e704f29148>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=scaled_X_train, \n",
    "          y=y_train, \n",
    "          epochs=300,\n",
    "          validation_data=(scaled_X_test, y_test), verbose=1 ,callbacks=[early_stop]         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.140512</td>\n",
       "      <td>0.391667</td>\n",
       "      <td>1.094477</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.131292</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>1.088694</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.123208</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>1.083057</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.114658</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>1.077301</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.106691</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>1.071715</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>0.346435</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.385848</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>0.345387</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.384787</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>0.344422</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.383703</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>0.343441</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.382703</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>0.342530</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.381663</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss  accuracy  val_loss  val_accuracy\n",
       "0    1.140512  0.391667  1.094477      0.500000\n",
       "1    1.131292  0.416667  1.088694      0.500000\n",
       "2    1.123208  0.433333  1.083057      0.500000\n",
       "3    1.114658  0.450000  1.077301      0.500000\n",
       "4    1.106691  0.475000  1.071715      0.500000\n",
       "..        ...       ...       ...           ...\n",
       "295  0.346435  0.966667  0.385848      0.966667\n",
       "296  0.345387  0.966667  0.384787      0.966667\n",
       "297  0.344422  0.966667  0.383703      0.966667\n",
       "298  0.343441  0.966667  0.382703      0.966667\n",
       "299  0.342530  0.966667  0.381663      0.966667\n",
       "\n",
       "[300 rows x 4 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics[['loss','val_loss']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8+yak3AAAACXBIWXMAAAsTAAALEwEAmpwYAAAyIklEQVR4nO3deXxU5bnA8d+byUZWQhKyEkC2sC8iiFpBEEVFg1qK1trqVakt6FVrvdhapeptvW21tb3UStVarUutXoFaWpUCbggCEnYCAYQsZF9nsifv/eNMwpDMJJNkkpkzeb6fTz4zc86ZM8/JCQ/vPOc976u01gghhDC/AG8HIIQQwjMkoQshhJ+QhC6EEH5CEroQQvgJSehCCOEnAr31wXFxcXrEiBHe+nghhDCl3bt3l2it452t81pCHzFiBLt27fLWxwshhCkppU65WiclFyGE8BOS0IUQwk9IQhdCCD/htRq6M42NjeTm5lJXV+ftUAQQGhpKamoqQUFB3g5FCOEGn0roubm5REZGMmLECJRS3g5nQNNaU1paSm5uLiNHjvR2OEIIN/hUyaWuro7Y2FhJ5j5AKUVsbKx8WxLCRHwqoQOSzH2InAshzMWnSi5CCD/UWAs7/gANNd6OpFdqGprYn1eFJ4YcHzIjg7Ez5nogqnNJQhdC9K0TH8Gm1fYX5v3WNwi4wEPTR+yMSgJJ6P6jqamJwED59YsBwFpgPN5/EKJTvRtLD7W0aC7+n82MT4ripdsu6PX+ZnsgJmd8robuC5YsWcL555/PxIkTWbt2LQD/+te/mDFjBlOnTmXBggUAWK1Wbr/9diZPnsyUKVN45513AIiIiGjb19tvv81tt90GwG233cbdd9/N7Nmzeeihh/jiiy+YM2cO06dP56KLLiIrKwuA5uZmHnzwQSZNmsSUKVP43e9+x+bNm1myZEnbfj/88EOuv/76fvhtCNFL1mLjMSzOu3G46UBeJQ/8NZP73tzT9rP81d2cqaxjyfQUb4fXKZ9tIv707wc5lF/l0X1OSI7isWsndrndSy+9xJAhQ6itreWCCy4gIyODu+66i48//piRI0dSVlYGwBNPPEF0dDT79+8HoLy8vMt95+bmsm3bNiwWC1VVVXzyyScEBgayadMmfvSjH/HOO++wdu1avvrqKzIzMwkMDKSsrIyYmBi+//3vU1xcTHx8PH/605/4j//4j979QoToD7ZiCImGoFBvR+KW32w6yifHSkiMPjfeC0bEsHB8gpeico/PJnRv+u1vf8u7774LQE5ODmvXruXSSy9t6489ZMgQADZt2sSbb77Z9r6YmJgu97106VIsFgsAlZWVfOc73+HYsWMopWhsbGzb7913391Wkmn9vFtvvZW//OUv3H777Xz++ee88sorHjpiIfqQrQginA4O6HPKbQ1szSrm9otH8ONrJng7nG7z2YTuTku6L2zdupVNmzbx+eefExYWxrx585g2bRpHjhxxex+O3f3a9+MODw9ve/6Tn/yEyy67jHfffZevvvqKefPmdbrf22+/nWuvvZbQ0FCWLl0qNXhhDtZiCB/q7Shc+teBM6z9+ATjEqOYmBxFU4smY5pvl1ZckRp6O5WVlcTExBAWFsaRI0fYvn07dXV1fPzxx5w8eRKgreSycOFC1qxZ0/be1pJLQkIChw8fpqWlpa2l7+qzUlKMP5yXX365bfnChQt5/vnnaWpqOufzkpOTSU5O5sknn+T222/33EEL0ZdsRRDuu/Xz32w6xt7cSt744jTPbT3O6KERTEyO8nZYPSIJvZ1FixbR1NTE+PHjWbVqFRdeeCHx8fGsXbuWG264galTp7Js2TIAHnnkEcrLy5k0aRJTp05ly5YtADz11FMsXryYiy66iKSkJJef9dBDD/Hwww8zffr0tuQNcOedd5KWlsaUKVOYOnUqr7/+etu6W265hWHDhjF+/Pg++g0I4WG2YojwzRZ6VkE1RwqqWTFvFJYARV5FLUumJZv2pjrliU7yPTFz5kzdfoKLw4cPS6LqwsqVK5k+fTp33HFHv3yenBPRK82N8EQczPsRzPuvPv+41RsOkhAVyvfmjep0u5c+Pcnvt2ZT19hCbWMzO360gAf/tpetWcV88tBlDBsS1uex9pRSarfWeqazdVKENZHzzz+f8PBwnn76aW+HIoR7bPYui/1wUVRrzTu7c0mJGdRlQt+4/wzBlgCunJjI5JRo4iJCWHVVOldMSPTpZN4VSegmsnv3bm+HIAYCraHB5pl9VZw2HsP7PqHnVdRSXd/E8WIrjc0tBFmcV5S11mQVVLNkegpPLJnUtjw9MYr0RHPWzltJQhdCnGvzE/CJh78FRiR6dn9OHDlTDUBjs+ZEsY1xiZFOt2tN/K7Wm5kkdCHEuc7sg+hhMGu5Z/YXGgUp53tmX53IKqxue36koMplws4qMLZLl4QuhPB7tiIYOh4uvtfbkbhUaq2nsKr+nGW7T5WTGBVKqa2e7SdKGTPUecL+LLsUgLGS0IUQfs9aDAmTvR2FSw1NLSx69hOKq+s7rLtyYgJ5FbW88UUOb3yR43Ifw2PDiAr1v6kVJaELIc7S2uiZ4sM3An1yrJji6noevGIso9u1wmcMH0xdQwuHznQ+DtSYhIhO15uVJPReiIiIwGq1ejsMITynrgJaGn3mRqC9ORWcqTx3+IzXdpwiJiyI784d5bInS1qsebse9oYkdD8gY6sLj2kd6tYHxl6pqmvkxue20dTS8ebH2y4a4TKZD2S+mwX+uQoK9nt2n4mT4aqnXK5etWoVw4YNY8WKFQCsXr2awMBAtmzZQnl5OY2NjTz55JNkZGR0+VFWq5WMjAyn73vllVf41a9+hVKKKVOm8Oqrr1JYWMjdd9/NiRMnAHjuuedITk5m8eLFHDhwAIBf/epXWK1WVq9e3TZo2KeffsrNN9/M2LFjefLJJ2loaCA2NpbXXnuNhIQErFYr99xzD7t27UIpxWOPPUZlZSX79u3jN7/5DQB//OMfOXToEL/+9a9789sV/sBWZDz6wOiIRwuqaWrRPLFkEuennR3JVCkYFe+fJZPe8t2E7gXLli3jvvvua0vob731Fu+//z733nsvUVFRlJSUcOGFF3Ldddd1OdZDaGgo7777bof3HTp0iCeffJJt27YRFxfXNvDWvffey9y5c3n33Xdpbm7GarV2Ob56Q0MDrcMnlJeXs337dpRSvPDCC/ziF7/g6aefdjpme1BQEP/93//NL3/5S4KCgvjTn/7E888/39tfn/AHVntC74cbgbpy2N69cH76UFIGD/JyNObgVkJXSi0CngUswAta66farR8OvATEA2XAt7TWub2KrJOWdF+ZPn06RUVF5OfnU1xcTExMDImJidx///18/PHHBAQEkJeXR2FhIYmJnd8oobXmRz/6UYf3bd68maVLlxIXZ1x0ah3rfPPmzW3jm1ssFqKjo7tM6K2DhIExccayZcs4c+YMDQ0NbWO3uxqzff78+bz33nuMHz+exsZGJk/23V4Noh/ZSoxHHyi5ZBVUERkaSHK0OSbG8AVdJnSllAVYAywEcoGdSqkNWutDDpv9CnhFa/1npdR84OfArX0RcF9bunQpb7/9NgUFBSxbtozXXnuN4uJidu/eTVBQECNGjOgwxrkzPX2fo8DAQFpaWtpedza2+j333MMDDzzAddddx9atW1m9enWn+77zzjv52c9+Rnp6ugzFK86yFYEKgLAh3o6ErIJq0hMjTTvyoTe400KfBWRrrU8AKKXeBDIAx4Q+AXjA/nwLsM6DMfarZcuWcdddd1FSUsJHH33EW2+9xdChQwkKCmLLli2cOnXKrf1UVlY6fd/8+fO5/vrreeCBB4iNjaWsrIwhQ4awYMECnnvuOe677762kktCQgJFRUWUlpYSERHBe++9x6JFi1x+XuvY6n/+85/blreO2d5aLy8vLycmJobZs2eTk5PDl19+yb59+3rxGxM+bd9bcHq7+9uf/tyY+zPA0ncxdaKlRfO/W7Ipqq7jYH4VN8ww50QT3uJOQk8BHHvo59Jx0uq9wA0YZZnrgUilVKzWutRxI6XUcmA5QFpaWk9j7lMTJ06kurqalJQUkpKSuOWWW7j22muZPHkyM2fOJD093a39uHrfxIkT+fGPf8zcuXOxWCxMnz6dl19+mWeffZbly5fz4osvYrFYeO6555gzZw6PPvoos2bNIiUlpdPPXr16NUuXLiUmJob58+e3TcbxyCOPsGLFCiZNmoTFYuGxxx7jhhtuAOAb3/gGmZmZbk2dJ0zqg0egrhKCu3ERcazzRkN/2HGyjGc+PEpUaCARIYEs8PE5PH1Nl+OhK6W+DizSWt9pf30rMFtrvdJhm2Tgf4GRwMfAjcAkrXWFq/3KeOjet3jxYu6//34WLFjgchs5JybW0myMRX7JA7DgJ96Oxi2r3tnHhr357HrkcsKCpc+GM70dDz0PGObwOtW+rI3WOh+jhY5SKgK4sbNkLryroqKCWbNmMXXq1E6TuTC5mjLQLV69SehMZS0/WXeQ+qZmwoIt/Oz6ycRGhDjdtr6pmY37z3DlxERJ5j3kzm9tJzBGKTUSI5HfBHzTcQOlVBxQprVuAR7G6PEyIOzfv59bbz33+m9ISAg7duzwUkRdGzx4MEePHvV2GKKvtU4u4cUuiK/vOM3mI4VMSR3MJ8dKmJEWw3fnOp98YsuRYqrqmsiYltzPUfqPLhO61rpJKbUSeB+j2+JLWuuDSqnHgV1a6w3APODnSimNUXJZ0dOAtNamuqo9efJkMjMzvR1Gn/DW9ITCQ9puEvJOC11rzfrMfC4eHcerd8wmY81nrMvMd5nQ12fmERcRzCWjfXccGV/n1vcarfVGYGO7ZY86PH8beLu3wYSGhlJaWkpsbKypkro/0lpTWlpKaKj0ATYtq3db6HtzKzldVsO9C8YAsGRaMj/9+yEu/cUWlIJgSwBPLpnEf288TGVtI7nltdx64XAC5Zb+HvOpQlVqaiq5ubkUFxd7OxSB8R9samqqt8MQPeXlksth+4iHF55n9Gm/8fxUjhZaqW1oAmDjgQJWvL6HEms910xO4oIRQ7jjkpFeidVf+FRCDwoKarvDUQjRS7YiCAiCQd7plppfUUuAgsQo41teVGgQP7/h7B3Jja99yT/2n2FcQiRrbpnhlRj9jXy3EcJfWYuN1rmXypd5FbUkRoW6LKG0XvzMmC4XQT3Fp1roQggPshV5daKK/IpaUmJcD6q1YHwCP79hMtdNlYTuKZLQhTCrukqo7WQAt6p8iOx8ELm+lFdRy4w01+UeS4Di5lm+ece4WUlCF8KMmhrg15OhvrLz7VK8U5tubtEUVNaRLMPe9itJ6EKYka3ISObTb4XhF7ne7rzL+i8mByXWehqbtST0fiYJXQgzap2IYtzVkH61d2Oxa2puYdepcpqaNSdKjLl2UyWh9ytJ6EKYUWsfcx+ZzBngL9tPsfrvh85ZNjIu3MXWoi9IQhfCjNqmivOd2+T/b08e6YmRPLFkEmD0Ox8hCb1fSUIXwoza7gL1Xgu9sqaRfx08Q3ML2Oqb2JdbySPXjOeCEd6f7WigkoQuhBnZio1JK4LDvBbCbzcf48VPT7a9Dg0K4FrpU+5VktCFMCOrd28aam7RbNibz4L0ofzMfjt/WLCFyNAgr8UkJKELYU62Yq+VW06V2nhu63GKq+v5+vmpJETJiJy+QsZyEcKMbMVe6+HyzIdH+euuHEbFh3NZuu/0shGS0IUwJ2uRV4bFrWlo4oODhdw8K41//2AeoUGWfo9BuCYlFyF8SYMN/vkQ1Fd3vl1Nab8n9N2nynn6gyxqG5tZMi2lXz9buEcSuhC+JG837PkLDE6DoE56sCRMhFH9e1v/bzYdJTOngoUTEpg53DtjrIvOSUIXwpe03jD0zbdg6HjvxuKgqLqOz7JLWHHZaH5wxThvhyNckBq6EL7EVmI8evGGIYB1e/J48j3jNv5/7j/D0j98TouGDCm1+DRpoQvhS2xFoCxemzYOjAnCn/nwKKfLavjORSP43eZsahua+f68UYweGuG1uETXpIUuhC9p7b0S4L1/mntyKjhdVgPAL9/P4tCZKr43bxQPLUr3WkzCPdJCF8KX2Io93nvlu6/uYlt2qdvb1ze3EBIYwJiECDbszccSoFg8RW7pNwNJ6EL4ElsxRHguoZ8otvL+wULmjo1nVLz75ZJpaYMZGRvOu3vyGJ8USXxkiMdiEn1HEroQvsRaDLFjPLKrxuYW3t6di1LwPzdOITG6+7foT06N9kgson+4VahTSi1SSmUppbKVUqucrE9TSm1RSu1RSu1TSvnGFCpCmInWxkVRD7TQtdZc89tP+P3W48w5L7ZHyVyYT5ctdKWUBVgDLARygZ1KqQ1aa8epSR4B3tJaP6eUmgBsBEb0QbxC+K/6amiq80gNffepco4WWrlldhrLLz3PA8EJM3Cn5DILyNZanwBQSr0JZACOCV0DUfbn0UC+J4MUwu9oDUWHoLHu7LJq+z8bex/07CIr1vqmHu3+1e2nCA0K4OGrxxMRIpXVgcKdM50C5Di8zgVmt9tmNfCBUuoeIBy43CPRCeGvjm+Gv9zgfN3gYRzIq2Tx7z7t1UdcNzVZkvkA46mzfTPwstb6aaXUHOBVpdQkrXWL40ZKqeXAcoC0tDQPfbQQJlRun+nnhhcg1OHCY3AYpF3EO/84TLAlgDW3zCAwQHV//wpmDJPxVgYadxJ6HjDM4XWqfZmjO4BFAFrrz5VSoUAcUOS4kdZ6LbAWYObMmbqHMQthflb7nKATrwfLuf8Mm5pb+PveM8xPH8rCCQleCE6YlTu9XHYCY5RSI5VSwcBNwIZ225wGFgAopcYDoUCxJwMVwq/YimDQkA7JHGDb8VJKrPUsmS4384ju6TKha62bgJXA+8BhjN4sB5VSjyulrrNv9gPgLqXUXuAN4DattbTAhXClkxmH1mXmERkayLxxMhuQ6B63auha640YXREdlz3q8PwQcLFnQxPCj1k73uLf2NzCq5+f4v0DBSyekiyzAYluk8G5hPAGW1GHFvp7+/J5/L1DNDS3sGzWMBdvFMI16dMkhDc4aaGv25NPyuBBfPTDeQRapK0luk/+aoTob4210FDdltAraxv5yboDfJpdQsa0ZEnmosfkL0eI/mazdwCzl1z+tiuHV7efYnhsGN+YKaUW0XNSchGiv7X2Qbff4r8+M5/JKdH8/Z5LvBiU8AfSQheiP5Ueh40PAlCsI7n1xR3sz6skY5r0ORe9JwldiP50Yivkfwljr2JTaSyfHCth7th4bpiR6u3IhB+QhC5Ef7KVGI/LXuVQcRORIYG8fPsFDAkP9m5cwi9IQheiP9mKYFAMWILIKqhmXGIkSvVg8C0hnJCELkR/shZB+FC01hwuqGJcYqS3IxJ+RHq5CNGPtLUIHR5HXnkt1XVNpEtCFx4kLXQh+snmI4WcPHWKjSea+dovtgCQnhTVxbuEcJ+00IXoJ6/vOM2vAyoZljycB0ePJWpQEOenySQUwnMkoQvRx7TWHCmoZltWHpHBNUxNH8PUS8d4Oyzhh6TkIkQfe+OLHK569hMGt1QaC9oNyiWEp0hCF6KP/W13DqPiw3nuevs4LeEycYXoG1JyEcLDahua2X6yFK01VbVNHDhdwq9nW5lam2ts4GKmIiF6SxK6EB72m38f5fmPTrS9Xha4jcV7/2C8UAEQLSMqir4hCV0ID2pu0azbk8clo+P44ZXjAEg7chg+A27bCFFJEJng3SCF35KELkQ3nCyx8VFWkcv1hdX1FFbV88g1E5g6bLCxMLvReEybAwFy2Ur0HUnoQnTDqnf2seNkWafbxEUEc/l4h1Z4gxWCwiSZiz4nCV0IN+VV1LLjZBkrLxvNHZeMdLndoGALoUGWswsaayA4vB8iFAOdJHQh3LQhMx+ApTNTienOcLcNNqOFLkQfk++AQrhpfWYe09MGMzy2m63tBpu00EW/kIQuhBuOFFRxpKCaJdNSuv9mKbmIfiIlFyEcvLr9lNNeLLnltVgCFNdMSer+TqXkIvqJWwldKbUIeBawAC9orZ9qt/7XwGX2l2HAUK31YA/GKUSfq2lo4ucbDxMREkh8ZMg56ywBiuWXnkdcRIiLd3eioQbCYj0UpRCudZnQlVIWYA2wEMgFdiqlNmitD7Vuo7W+32H7e4DpfRCrEH3qw0OF1DQ08+J3LmDOKA8m4AarlFxEv3CnhT4LyNZanwBQSr0JZACHXGx/M/CYZ8LzX+v25PH7rdlobbwemxDJmltmeDeoAeS/3t7Hl6fLz1lWbK0nKTqU2SOHePbDGmuk5CL6hTsXRVOAHIfXufZlHSilhgMjgc0u1i9XSu1SSu0qLi7ubqx+Q2vN/27JxlrXxJiECAYFW/jH/jMUV9d7O7QB4USxlb/uyiEiNJAxCRFtPxeNiuUniycQEODhSZsb5KKo6B+evih6E/C21rrZ2Uqt9VpgLcDMmTO1hz/bNA7mV5FdZOXJJZP41oXD2ZZdwjdf2MGRgiriI2Ws7L62LjMfpeAP3zqfhKjQvv0wraXkIvqNOwk9D3AcHi7VvsyZm4AVvQ3KV2mtWbZ2O5k5FQD854IxrLhsNA/+bS9xESGsuirdrf2sz8wjMEBxzWSjx0TrzO9ZBdV8bYwkdHcUVNZx7f9+SmVtY7ff29jcwpzzYvs+mQM01QFaSi6iX7iT0HcCY5RSIzES+U3AN9tvpJRKB2KAzz0aoQ/Zl1vJFyfLuGpSIgfzq/j34UK+N3cU/9x/BjAS/KBgS6f7aG7RbNibz7xx8W13G8ZGhBAfGcKRguo+PwZ/8e6ePIqr67nzkpEEWrp3O4VScN3U5D6KrJ0Gm/EoLXTRD7pM6FrrJqXUSuB9jG6LL2mtDyqlHgd2aa032De9CXhTa+2XpZTahmbe2pVDsCWAp26cwjMfZPH27lxyymuwNRgVpg8PF3aaKFpaNJsOF9pH4zv3MkR6YiQH86uoaWgiLPjc01Jirae5xS9/rT22PjOPGWmDeWTxBG+H0jlJ6KIfuVVD11pvBDa2W/Zou9erPReWb2lsbmHB01vJr6zjyokJRA8KIj0pCltDM5sOGzehBAYo1u/J6zShP7L+AK/vOE14sOXc0fiACUlRPP/xCS56ajOf/dd8wkOMU/N/X+bywFt7++7gTOzxjIneDqFrjTXGo5RcRD+QO0Xd8OmxEvIr6/jupedx28UjgLN17/WZxuWEm2YN480vciizNTDEycBNtQ3NrN+Tx9fGxHHf5R1LM9+dO4rwkECe+fAoHxwq4PrpqQD8dWcOw4YM4ntzR/fhEZpPcGAA107twV2b/U1a6KIfSULvQk5ZDa/tOEX0oCB+cMU4ggONeu3YBCOh78utJG1IGN+cNZy/bD/Ni5+eYO7YoYyKDyfW4a7CTYcLsTU08725ozh/eMd+zkPCg1l52Wj+ujOHN77IIWVwGNb6RnacLOOBhWP55uy0/jlg4VmS0EU/koTeiabmFq5+9hOq65v41oVpbckcICIkkFHx4RwvtjE5NZrxSZGkJ0ayZstx1mw5ztTUaNavvKRt+w8OFRIfGcLs81zfgRgQoLhhRgq/25zNN543ri0HKMiY1k8X8ITntSZ0KbmIfiAJvRMnS2xU1zdx7/zR3D1vVIf1r94xm5MlNiYlR6OU4pX/mMWxIitbjhTxwqcnyS6qZvRQoyV/KL+SacMGY+nippUVl43molFxtNivLQ8JD+7+cK3Cd7TW0KWFLvqBJPROtHYjXDQpqUPPE4DkwYNIHjyo7fXQqFCGRoUyJiGClz47ybo9+Tx45TjqGps5WWJr63femdAgi2fHERH9p6YMjn0AuuXsslOfGY+S0EU/kITeiSMFVVgCFKOGdu8f49DIUC4eHcf6vXn84IqxZBdZadEwLjGqjyIVPmH77+HjX3ZcHhQOg2L6Px4x4EhC70RWQTWj4sMJCez8ZiFnMqal8ODf9vLl6XJOlhhfu9OTIj0dovAlVfkQkQh3vH/u8tDB0kIX/UISeieOFFQzPa1nLasrJybw43cDWLcnn5DAAEICAxghtXD/Zi2CyASIGeHtSMQAJVPQuVBd10hueS3piT1rVUeGBnH5hAT+sf8Mn2aXMCklussLosLkbMUQPtTbUYgBTBK6C0cLjQuiPU3oAEumpVBma+BIQTWLezJ1mTAXWzFESEIX3iMJHWOMld/++xi55TVtyw6fMRL6uF4k9Llj4xkcFoQlQLF4ivQl92ta21voMlqm8B6poQPZxVae+fAolgDFisuMW+yzCqqJDAkkxaFbYncFBwaw8rLRFFbVdZijUviZugpobpCELrxKEjpn+5vnV9Q6LKtiXGIkSvWu7n3n187r1fuFSdhKjEcpuQgvkpILcORMFWAk9OYWzT1v7GFvTqV0MxTusxqjbkoLXXiTJHSM8gpAfkUdnx8v5e9785mcGs2NM1K9HJkwDZskdOF9UnLhbMklr6KWdZl5RIQE8tqdswkN6v4NRWKAstonPZeSi/CiAZ/Qq+oayauoJTY8mFJbA+/ty2fxlOSOyfz1ZZC7y5i/7LIfw8zbvROw8K4v/giFB+Ha38CXr8C/Hzd6uDTWgAqAMBmHR3jPgC+5HLW3zueNM1pWdY0tLJl27vRwtDTD0fchZji0NMHJj/o7TOErjn0Ih+2zLp74yOjZMiEDpt4MV/0CAuRbnfCeAd9CP2xP6AvGD+WdL3MZGhnScbTDmlJAG/9oD/zf2a/XYuCxFRmjKjY3Gc/j02HxM96OSghAWuhkFVQRGRrIBSOMWYSunZrc8RZ9xx4MEfFnL4CJgcdaDGioKTGey0VQ4UMGfAv9yJlq0hMjiY8M4Y/fnsmskR2nhzunB0N4PFil5DIgaX32b8FaZDwfPse7MQnhYMC20HPLaziUX0VWQTXp9nHKF05IIHpQUMeNHW8aCR9q3BXY1NB/wQrfUF9l1MwBqguM0ou00IUPGZAt9DOVtXztF1uwz/LGxOQuJp5oX3IB4yt3lIzPMqA4XjspPgJoSejCpwzIhH66tAat4f7LxzI5NYqLR8d1/gZbEViCITT67PCo1iJJ6AON47WTwoPGo/Q7Fz5kQCb0UpvxtfmKiQmMT3JjWrjWi19KnW2R2aSny4BjdZLQZfxz4UPcqqErpRYppbKUUtlKqVUutvmGUuqQUuqgUup1z4bpWSXWegDiItwcAdFxWNQISegDVus5DxwERdJCF76nyxa6UsoCrAEWArnATqXUBq31IYdtxgAPAxdrrcuVUj79V15SXY9SMCQ82L032IogIsF47lhyEQOLrRhQED8Wzuw1lkkNXfgQd0ous4BsrfUJAKXUm0AGcMhhm7uANVrrcgCtte9lu5Zm41bt+mpGf1VG8qDzu54S7shGKM2G8lOQMNlYFhIBQWGQvQnSF0PcaDi9A3J2nPveEZdAyozuxVhdCAfeNmLtqaBBMP1WCArt+T4cndpmDHkgjDtDw2IhMslI6JYQCJEROYXvcCehpwA5Dq9zgdntthkLoJT6DLAAq7XW/2q/I6XUcmA5QFpaWk/i7bm8L+G9+wC4Djgw6IfAta63b2mBt241bvUHSJpydl3iFPjqE9j6c/j6i8Z+iw6d+/7UWXDnh92LcddL8NFT3XuPM5FJMH5x7/cDsH4FlJ3wzL78waj5kDQVjv7LeOzlePlCeJKnLooGAmOAeUAq8LFSarLWusJxI631WmAtwMyZM7WHPts91WeMx2/+DV5fyrDgqs63b6wxkvllj8Cc70Nw+Nl1t2+ElxaBtfDsvmd8G678ufH67/dC7s6exRgWB/+5t/vvBSOe380Aa0HP3u80pgKYtRwWPOa5fZpZUBgEBMBF9xrfhoTwIe4k9DxgmMPrVPsyR7nADq11I3BSKXUUI8H3IKv1kdYLWomTaCSQREt159s32ucXDYs5N5mDMQBTZAKUHIPmRqgth6gUoxwDRgu59WakbsVYYtTqW/fTXYEhZ/fjCQ024/cQldzzmPyV/D6ED3Knl8tOYIxSaqRSKhi4CdjQbpt1GK1zlFJxGCUY3/qe3prQw+Mp1VHEqcrOt2+wGo9B4c7Xhw+13/5d0rbfs+vijURYb+1mjEVne9H0hCUIBg3x3AXbthuqfPoatxDCrsuErrVuAlYC7wOHgbe01geVUo8rpa6zb/Y+UKqUOgRsAX6otS7tq6B7xFoEg4ZQ06wo1lEMObca1FGDvYUeHOZ8fcRQqC2D6vyzrx3XQfcH8bIW9T55Rgz13OBhNpm0QQgzcauGrrXeCGxst+xRh+caeMD+45tsRRAeT0l1A6U6mpTm8s63by25tC+3tAq3311adNj+ul0LHYwbkoZ0Y5JomwdG7wuP99zwvm0t9C7upBVC+ISBMziXrQQihrLteAklRBPRVNH59u6UXAAK7b1bnCX07tx81Fqv7k3JpfWzPXXTU1uZSlroQpjBwEnoVqOFvi4zj8bQOILqSmgbncuZhi5a6K1lCGd3DPak5OKpenXE0D5I6HLzjBBmMHASuq0YW9AQdpwsIzk1DdXcAHWdXBjtsuRiT3KFB41bwYMdej2E2UsU3Sl9eKpeHR5vDPPaWNe7/YDxn0zoYAh0845aIYRXDYyE3lgH9VUcqgpGa5gwepSxvLOWbFvJxcVFUceySuvAXa0Cg41E2KMWei/r1W1xeeDCqP26gxDCHAZGQrcn7m0FFqYOG0x8Yuo5y53qquQSEgmB9tvrndW9u1v68FS9uq3c44Gyi/26gxDCHPxr+Nzc3fDy1dDkvNywtyKEJRcnQ0StseCVDPj2ehh+UceNG2zGo6uErpRxE1DFqbMDdzmKSIBD62F1dDcOQPW+Rdwayx/n924/rSZe75n9CCH6nH8l9IK9RjKfs/KcRPzpsRI+O13DrPnXs+yCYRBkgYVPwIc/MQZZcpbQG23G4EsBFtefd80zkPsFpF/Tcd2CxyC7m2O5xI7ufb06aSpc+bPOrw90x4QMz+xHCNHn/Cuht16EvHy1cdck0NKi+eH2zUwYHcWLl086u+2clfDvn7q+q7KhxnXrvNWYy40fZ4ZdYPz0twALzFnR/58rhPA6/6qh24pgUExbMgfIzK3gTGUd101rN11cQIC9z7arhG7rOqELIYQP8a+Ebu3YK+NgnlF6uGDEkI7bh8e57lrYKAldCGEu/pXQbSUdeokcKagmKjSQpGgnEz6Ed9ITpaHGdZdFIYTwQX6W0DuOVnikoJr0xCiUs4kIOutaKCUXIYTJ+FdCtxaf00LXWpNVUM24RBfThIXHG2UaZ0MASMlFCGEy/pPQG+ugvvKcGnpueS3W+ibSkzpJ6M31xq3y7TXYpOQihDAV/0noNfaJJhxKLju/KgNgUrKLm3va7qp0MsNPQ43rsdCFEMIH+U9CdzJa4brMfFJjBjEl1UVCbxu33EnXxUbbuQNuCSGEj/OfhN5utMLi6no+PVZMxrRk5xdEHbZ12hddSi5CCJPxn4TebrTC9/bl06IhY1qK6/eExRqPNWXnLm9qgJYmKbkIIUzFfxJ6u9EK12XmMz4pirEJLi6IwtkWeOvY560aWwfmkpKLEMI8/CuhB0dAcBgnS2zszalgSfvb/dtr7ZbY0C6ht460KCUXIYSJ+E9Cd7jtf31mHkrRcfyW9ixBYAk+O5lFq67GQhdCCB/kPwndPruO1pr1mfnMHjmEpOhBXb8vKKyTkoskdCGEefhRQi/BGjSEJb/fxskSG0s6uxjqKDjibImllZRchBAm5D8J3VpETkM4e3MqyJiWzOKpXZRbWgWHOUnorSUXuSgqhDAP/5jgorkJakrJCY8kPjKEZ2+a7v57nZVcWmvq0m1RCGEi/tFCrykFNMdrQkl3NRCXK85KLq0JXkouQggTcSuhK6UWKaWylFLZSqlVTtbfppQqVkpl2n/u9HyonbDf6Xm4qicJXUouQgj/0GXJRSllAdYAC4FcYKdSaoPW+lC7Tf+qtV7ZBzGeq6EGGmvPXVZ2AoAzTVFcmhjVvf1JyUUI4SfcqaHPArK11icAlFJvAhlA+4TeP3b+ET581OmqQmI8V3JRARDoZJYjIYTwUe4k9BQgx+F1LjDbyXY3KqUuBY4C92utc9pvoJRaDiwHSEtL6360ACPnwlW/7LD4veMN5B1IZPTQbpZJXJVcgsLB1aBeQgjhgzzVy+XvwBta63ql1HeBPwPz22+ktV4LrAWYOXOmk2mC3JA8zfhpZ33WLkbG2QgNsnRvf0HOErpVyi1CCNNx56JoHjDM4XWqfVkbrXWp1rre/vIF4HzPhOe+IwVVrqea60xwBLQ0QnPj2WWNNXKXqBDCdNxJ6DuBMUqpkUqpYOAmYIPjBkqpJIeX1wGHPRdi16z1TeSU1TK+Rwnd3hJ3bKU32IySixBCmEiXJRetdZNSaiXwPmABXtJaH1RKPQ7s0lpvAO5VSl0HNAFlwG19GHMHRwurARjX3R4ucLaveYMNBg0++1xKLkIIk3Grhq613ghsbLfsUYfnDwMPezY09+2yzx06IbkHCb21r7lj18XGGgjpQWtfCCG8yC/uFF2fmc/U1GhSBrsxumJ7bSUXhyF0Zfo5IYQJmT6hZxdVczC/qvOp5jrjbJKLBptcFBVCmI7pE/q246UAXDExoWc7aL342b7kIgldCGEypk/oeeW1BFsCSHZnMgtnpOQihPATph8+N6+iluTBoQQE9PCuztaW+I61cGyT8byxRgbmEkKYjukTen5FLck9uRjaKiIRUs6HitPGD8Dg4TBslmcCFEKIfmL6hJ5XUculY+J7voOgULhrs+cCEkIILzF1Db2hqYWi6vretdCFEMJPmDqhF1bVoTU9638uhBB+xtQJPbfcmOgiJUYSuhBCmDqh51UYCT0pWiaiEEIIUyf07CIrQRbFsCHSZ1wIIUyd0LMKqhgVH0GQxdSHIYQQHmHqTHikoLr7c4gKIYSfMm1Cr6xp5ExlHelJPRgyVwgh/JBpE/qRgiqAnk07J4QQfsi0CT3LPkuRlFyEEMJg2oR++Ew10YOCSIySLotCCAEmTuhZBVWMS4xEqR6OsiiEEH7GlAm9pUVztNDKeCm3CCFEG1Mm9LyKWqz1TYxLlB4uQgjRypQJ/UiB/YJokrTQhRCilSkTenaRMV3cmKEyq5AQQrQyZULPq6hhcFgQkaFB3g5FCCF8hikTen5FXc8nhRZCCD/lVkJXSi1SSmUppbKVUqs62e5GpZRWSs30XIgd9XoeUSGE8ENdJnSllAVYA1wFTABuVkpNcLJdJPCfwA5PB9leXnktqTKphRBCnMOdFvosIFtrfUJr3QC8CWQ42e4J4H+AOg/G10FVXSPV9U0kD5Y7RIUQwpE7CT0FyHF4nWtf1kYpNQMYprX+R2c7UkotV0rtUkrtKi4u7nawYJRbAFIGy6QWQgjhqNcXRZVSAcAzwA+62lZrvVZrPVNrPTM+Pr5Hn5dnn0dUWuhCCHEudxJ6HjDM4XWqfVmrSGASsFUp9RVwIbChry6Mnm2hSw1dCCEcuZPQdwJjlFIjlVLBwE3AhtaVWutKrXWc1nqE1noEsB24Tmu9qy8CTogKZeGEBOIiQvpi90IIYVqBXW2gtW5SSq0E3gcswEta64NKqceBXVrrDZ3vwbOumJjIFRMT+/MjhRDCFLpM6ABa643AxnbLHnWx7bzehyWEEKK7THmnqBBCiI4koQshhJ+QhC6EEH5CEroQQvgJSehCCOEnJKELIYSfkIQuhBB+QmmtvfPBShUDp3r49jigxIPheJMci2+SY/FNciwwXGvtdDAsryX03lBK7dJa9+kkGv1FjsU3ybH4JjmWzknJRQgh/IQkdCGE8BNmTehrvR2AB8mx+CY5Ft8kx9IJU9bQhRBCdGTWFroQQoh2JKELIYSfMF1CV0otUkplKaWylVKrvB1PdymlvlJK7VdKZSqldtmXDVFKfaiUOmZ/jPF2nM4opV5SShUppQ44LHMauzL81n6e9tknEvcZLo5ltVIqz35uMpVSVzuse9h+LFlKqSu9E3VHSqlhSqktSqlDSqmDSqn/tC833Xnp5FjMeF5ClVJfKKX22o/lp/blI5VSO+wx/9U+CxxKqRD762z7+hE9+mCttWl+MGZMOg6cBwQDe4EJ3o6rm8fwFRDXbtkvgFX256uA//F2nC5ivxSYARzoKnbgauCfgMKYZ3aHt+N341hWAw862XaC/W8tBBhp/xu0ePsY7LElATPszyOBo/Z4TXdeOjkWM54XBUTYnwcBO+y/77eAm+zL/wB8z/78+8Af7M9vAv7ak881Wwt9FpCttT6htW4A3gQyvByTJ2QAf7Y//zOwxHuhuKa1/hgoa7fYVewZwCvasB0YrJRK6pdA3eDiWFzJAN7UWtdrrU8C2Rh/i16ntT6jtf7S/rwaOAykYMLz0smxuOLL50Vrra32l0H2Hw3MB962L29/XlrP19vAAqWU6u7nmi2hpwA5Dq9z6fyE+yINfKCU2q2UWm5flqC1PmN/XgAkeCe0HnEVu1nP1Up7KeIlh9KXKY7F/jV9OkZr0NTnpd2xgAnPi1LKopTKBIqADzG+QVRorZvsmzjG23Ys9vWVQGx3P9NsCd0fXKK1ngFcBaxQSl3quFIb37lM2ZfUzLHbPQeMAqYBZ4CnvRpNNyilIoB3gPu01lWO68x2XpwciynPi9a6WWs9DUjF+OaQ3tefabaEngcMc3idal9mGlrrPPtjEfAuxokubP3aa38s8l6E3eYqdtOdK611of0fYQvwR85+fffpY1FKBWEkwNe01v9nX2zK8+LsWMx6XlpprSuALcAcjBJXoH2VY7xtx2JfHw2UdvezzJbQdwJj7FeKgzEuHmzwckxuU0qFK6UiW58DVwAHMI7hO/bNvgOs906EPeIq9g3At+29Ki4EKh1KAD6pXS35eoxzA8ax3GTviTASGAN80d/xOWOvs74IHNZaP+OwynTnxdWxmPS8xCulBtufDwIWYlwT2AJ83b5Z+/PSer6+Dmy2f7PqHm9fDe7B1eOrMa5+Hwd+7O14uhn7eRhX5fcCB1vjx6iV/Rs4BmwChng7Vhfxv4HxlbcRo/53h6vYMa7yr7Gfp/3ATG/H78axvGqPdZ/9H1iSw/Y/th9LFnCVt+N3iOsSjHLKPiDT/nO1Gc9LJ8dixvMyBdhjj/kA8Kh9+XkY/+lkA38DQuzLQ+2vs+3rz+vJ58qt/0II4SfMVnIRQgjhgiR0IYTwE5LQhRDCT0hCF0IIPyEJXQgh/IQkdCGE8BOS0IUQwk/8P8pHgtOS7rcEAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics[['accuracy','val_accuracy']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3816627264022827, 0.9666666388511658]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(scaled_X_test,y_test,verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ready Model for Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = len(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=4,activation='relu'))\n",
    "\n",
    "# Last layer for multi-class classification of 3 species\n",
    "model.add(Dense(units=3,activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 1.0712 - accuracy: 0.3516\n",
      "Epoch 2/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 1.0824 - accuracy: 0.3242\n",
      "Epoch 3/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.0694 - accuracy: 0.3346\n",
      "Epoch 4/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.0386 - accuracy: 0.3615\n",
      "Epoch 5/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.0438 - accuracy: 0.3160\n",
      "Epoch 6/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.0299 - accuracy: 0.3477\n",
      "Epoch 7/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 1.0185 - accuracy: 0.3286\n",
      "Epoch 8/300\n",
      "5/5 [==============================] - 0s 756us/step - loss: 1.0080 - accuracy: 0.3682\n",
      "Epoch 9/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.0263 - accuracy: 0.4184\n",
      "Epoch 10/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.0089 - accuracy: 0.5187\n",
      "Epoch 11/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.0157 - accuracy: 0.4792\n",
      "Epoch 12/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.0064 - accuracy: 0.4772\n",
      "Epoch 13/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.9763 - accuracy: 0.5593\n",
      "Epoch 14/300\n",
      "5/5 [==============================] - 0s 987us/step - loss: 1.0052 - accuracy: 0.5311\n",
      "Epoch 15/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.9808 - accuracy: 0.5572\n",
      "Epoch 16/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.9792 - accuracy: 0.5268\n",
      "Epoch 17/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.9949 - accuracy: 0.5166\n",
      "Epoch 18/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.9810 - accuracy: 0.5539\n",
      "Epoch 19/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.9488 - accuracy: 0.6034\n",
      "Epoch 20/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.9634 - accuracy: 0.5727\n",
      "Epoch 21/300\n",
      "5/5 [==============================] - 0s 756us/step - loss: 0.9555 - accuracy: 0.5787\n",
      "Epoch 22/300\n",
      "5/5 [==============================] - 0s 742us/step - loss: 0.9631 - accuracy: 0.5545\n",
      "Epoch 23/300\n",
      "5/5 [==============================] - 0s 749us/step - loss: 0.9360 - accuracy: 0.6058\n",
      "Epoch 24/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.9369 - accuracy: 0.5980\n",
      "Epoch 25/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.9434 - accuracy: 0.5954\n",
      "Epoch 26/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.9244 - accuracy: 0.6237\n",
      "Epoch 27/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.9264 - accuracy: 0.6116\n",
      "Epoch 28/300\n",
      "5/5 [==============================] - 0s 735us/step - loss: 0.9036 - accuracy: 0.6294\n",
      "Epoch 29/300\n",
      "5/5 [==============================] - 0s 995us/step - loss: 0.9253 - accuracy: 0.6072\n",
      "Epoch 30/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.8876 - accuracy: 0.6338\n",
      "Epoch 31/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.9073 - accuracy: 0.6125\n",
      "Epoch 32/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.9058 - accuracy: 0.6321\n",
      "Epoch 33/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.9064 - accuracy: 0.6213\n",
      "Epoch 34/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.8995 - accuracy: 0.6209\n",
      "Epoch 35/300\n",
      "5/5 [==============================] - 0s 999us/step - loss: 0.8665 - accuracy: 0.6583\n",
      "Epoch 36/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.8679 - accuracy: 0.6535\n",
      "Epoch 37/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.8778 - accuracy: 0.6805\n",
      "Epoch 38/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.8867 - accuracy: 0.6067\n",
      "Epoch 39/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.8926 - accuracy: 0.6259\n",
      "Epoch 40/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.8588 - accuracy: 0.6875\n",
      "Epoch 41/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.8585 - accuracy: 0.6775\n",
      "Epoch 42/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.8649 - accuracy: 0.6611\n",
      "Epoch 43/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.8378 - accuracy: 0.6602\n",
      "Epoch 44/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.8620 - accuracy: 0.6507\n",
      "Epoch 45/300\n",
      "5/5 [==============================] - 0s 998us/step - loss: 0.8441 - accuracy: 0.6781\n",
      "Epoch 46/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.8396 - accuracy: 0.6620\n",
      "Epoch 47/300\n",
      "5/5 [==============================] - 0s 745us/step - loss: 0.8388 - accuracy: 0.6841\n",
      "Epoch 48/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.8508 - accuracy: 0.6633\n",
      "Epoch 49/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.8419 - accuracy: 0.6516\n",
      "Epoch 50/300\n",
      "5/5 [==============================] - 0s 755us/step - loss: 0.8400 - accuracy: 0.6854\n",
      "Epoch 51/300\n",
      "5/5 [==============================] - 0s 755us/step - loss: 0.8387 - accuracy: 0.6607\n",
      "Epoch 52/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.8064 - accuracy: 0.7123\n",
      "Epoch 53/300\n",
      "5/5 [==============================] - 0s 999us/step - loss: 0.8181 - accuracy: 0.6881\n",
      "Epoch 54/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7955 - accuracy: 0.7247\n",
      "Epoch 55/300\n",
      "5/5 [==============================] - 0s 742us/step - loss: 0.7941 - accuracy: 0.7173\n",
      "Epoch 56/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.8316 - accuracy: 0.6452\n",
      "Epoch 57/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.8056 - accuracy: 0.6730\n",
      "Epoch 58/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.7946 - accuracy: 0.6964\n",
      "Epoch 59/300\n",
      "5/5 [==============================] - 0s 996us/step - loss: 0.8016 - accuracy: 0.6808\n",
      "Epoch 60/300\n",
      "5/5 [==============================] - 0s 749us/step - loss: 0.7865 - accuracy: 0.6948\n",
      "Epoch 61/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.7727 - accuracy: 0.7312\n",
      "Epoch 62/300\n",
      "5/5 [==============================] - 0s 998us/step - loss: 0.7762 - accuracy: 0.7181\n",
      "Epoch 63/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.7706 - accuracy: 0.6777\n",
      "Epoch 64/300\n",
      "5/5 [==============================] - 0s 750us/step - loss: 0.7575 - accuracy: 0.7046\n",
      "Epoch 65/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7612 - accuracy: 0.7059\n",
      "Epoch 66/300\n",
      "5/5 [==============================] - 0s 989us/step - loss: 0.7724 - accuracy: 0.6968\n",
      "Epoch 67/300\n",
      "5/5 [==============================] - 0s 988us/step - loss: 0.7669 - accuracy: 0.6955\n",
      "Epoch 68/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7432 - accuracy: 0.7246\n",
      "Epoch 69/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.7430 - accuracy: 0.6872\n",
      "Epoch 70/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.7593 - accuracy: 0.6755\n",
      "Epoch 71/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7574 - accuracy: 0.6929\n",
      "Epoch 72/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7241 - accuracy: 0.6946\n",
      "Epoch 73/300\n",
      "5/5 [==============================] - 0s 749us/step - loss: 0.7243 - accuracy: 0.6872\n",
      "Epoch 74/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7467 - accuracy: 0.6898\n",
      "Epoch 75/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.7289 - accuracy: 0.6846\n",
      "Epoch 76/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.7109 - accuracy: 0.7007\n",
      "Epoch 77/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.7535 - accuracy: 0.6738\n",
      "Epoch 78/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.7109 - accuracy: 0.7055\n",
      "Epoch 79/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.7140 - accuracy: 0.6847\n",
      "Epoch 80/300\n",
      "5/5 [==============================] - 0s 990us/step - loss: 0.7386 - accuracy: 0.6747\n",
      "Epoch 81/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.7119 - accuracy: 0.6777\n",
      "Epoch 82/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.6857 - accuracy: 0.7177\n",
      "Epoch 83/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 760us/step - loss: 0.7028 - accuracy: 0.7025\n",
      "Epoch 84/300\n",
      "5/5 [==============================] - 0s 998us/step - loss: 0.6875 - accuracy: 0.7285\n",
      "Epoch 85/300\n",
      "5/5 [==============================] - 0s 746us/step - loss: 0.6805 - accuracy: 0.7207\n",
      "Epoch 86/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.6710 - accuracy: 0.6938\n",
      "Epoch 87/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.6843 - accuracy: 0.6912\n",
      "Epoch 88/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.6764 - accuracy: 0.7138\n",
      "Epoch 89/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.6681 - accuracy: 0.7212\n",
      "Epoch 90/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.6799 - accuracy: 0.7164\n",
      "Epoch 91/300\n",
      "5/5 [==============================] - 0s 630us/step - loss: 0.6658 - accuracy: 0.7212\n",
      "Epoch 92/300\n",
      "5/5 [==============================] - 0s 740us/step - loss: 0.6647 - accuracy: 0.7056\n",
      "Epoch 93/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.6890 - accuracy: 0.6882\n",
      "Epoch 94/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.6416 - accuracy: 0.7333\n",
      "Epoch 95/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.6658 - accuracy: 0.6895\n",
      "Epoch 96/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6792 - accuracy: 0.6969\n",
      "Epoch 97/300\n",
      "5/5 [==============================] - 0s 989us/step - loss: 0.6689 - accuracy: 0.7034\n",
      "Epoch 98/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.6731 - accuracy: 0.6874\n",
      "Epoch 99/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.6578 - accuracy: 0.7208\n",
      "Epoch 100/300\n",
      "5/5 [==============================] - 0s 739us/step - loss: 0.6458 - accuracy: 0.7421\n",
      "Epoch 101/300\n",
      "5/5 [==============================] - 0s 989us/step - loss: 0.6752 - accuracy: 0.7104\n",
      "Epoch 102/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.6241 - accuracy: 0.7095\n",
      "Epoch 103/300\n",
      "5/5 [==============================] - 0s 756us/step - loss: 0.6454 - accuracy: 0.7121\n",
      "Epoch 104/300\n",
      "5/5 [==============================] - 0s 747us/step - loss: 0.6410 - accuracy: 0.7173\n",
      "Epoch 105/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.6500 - accuracy: 0.6744\n",
      "Epoch 106/300\n",
      "5/5 [==============================] - 0s 745us/step - loss: 0.6329 - accuracy: 0.6974\n",
      "Epoch 107/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.6353 - accuracy: 0.6961\n",
      "Epoch 108/300\n",
      "5/5 [==============================] - 0s 754us/step - loss: 0.6172 - accuracy: 0.7248\n",
      "Epoch 109/300\n",
      "5/5 [==============================] - 0s 754us/step - loss: 0.6359 - accuracy: 0.7044\n",
      "Epoch 110/300\n",
      "5/5 [==============================] - 0s 989us/step - loss: 0.6462 - accuracy: 0.6783\n",
      "Epoch 111/300\n",
      "5/5 [==============================] - 0s 754us/step - loss: 0.6308 - accuracy: 0.6931\n",
      "Epoch 112/300\n",
      "5/5 [==============================] - 0s 744us/step - loss: 0.5949 - accuracy: 0.7508\n",
      "Epoch 113/300\n",
      "5/5 [==============================] - 0s 998us/step - loss: 0.6157 - accuracy: 0.7126\n",
      "Epoch 114/300\n",
      "5/5 [==============================] - 0s 995us/step - loss: 0.6459 - accuracy: 0.6636\n",
      "Epoch 115/300\n",
      "5/5 [==============================] - 0s 998us/step - loss: 0.6226 - accuracy: 0.6944\n",
      "Epoch 116/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.6208 - accuracy: 0.7100\n",
      "Epoch 117/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.5829 - accuracy: 0.7235\n",
      "Epoch 118/300\n",
      "5/5 [==============================] - 0s 755us/step - loss: 0.6082 - accuracy: 0.7096\n",
      "Epoch 119/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.5992 - accuracy: 0.7117\n",
      "Epoch 120/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.6032 - accuracy: 0.7213\n",
      "Epoch 121/300\n",
      "5/5 [==============================] - 0s 996us/step - loss: 0.6004 - accuracy: 0.7018\n",
      "Epoch 122/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5786 - accuracy: 0.7356\n",
      "Epoch 123/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5863 - accuracy: 0.7113\n",
      "Epoch 124/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.5938 - accuracy: 0.6905\n",
      "Epoch 125/300\n",
      "5/5 [==============================] - 0s 984us/step - loss: 0.5728 - accuracy: 0.7326\n",
      "Epoch 126/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.5718 - accuracy: 0.7278\n",
      "Epoch 127/300\n",
      "5/5 [==============================] - 0s 756us/step - loss: 0.5545 - accuracy: 0.7435\n",
      "Epoch 128/300\n",
      "5/5 [==============================] - 0s 998us/step - loss: 0.5485 - accuracy: 0.7396\n",
      "Epoch 129/300\n",
      "5/5 [==============================] - 0s 756us/step - loss: 0.5411 - accuracy: 0.7691\n",
      "Epoch 130/300\n",
      "5/5 [==============================] - 0s 751us/step - loss: 0.5729 - accuracy: 0.6953\n",
      "Epoch 131/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5681 - accuracy: 0.7140\n",
      "Epoch 132/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.5738 - accuracy: 0.7344\n",
      "Epoch 133/300\n",
      "5/5 [==============================] - 0s 740us/step - loss: 0.5940 - accuracy: 0.7092\n",
      "Epoch 134/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.5521 - accuracy: 0.7409\n",
      "Epoch 135/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.6020 - accuracy: 0.6662\n",
      "Epoch 136/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.5377 - accuracy: 0.7422\n",
      "Epoch 137/300\n",
      "5/5 [==============================] - 0s 998us/step - loss: 0.5487 - accuracy: 0.7192\n",
      "Epoch 138/300\n",
      "5/5 [==============================] - 0s 998us/step - loss: 0.5528 - accuracy: 0.7492\n",
      "Epoch 139/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.5494 - accuracy: 0.7327\n",
      "Epoch 140/300\n",
      "5/5 [==============================] - 0s 749us/step - loss: 0.5580 - accuracy: 0.7105\n",
      "Epoch 141/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.5736 - accuracy: 0.6945\n",
      "Epoch 142/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.5378 - accuracy: 0.7461\n",
      "Epoch 143/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.5017 - accuracy: 0.7622\n",
      "Epoch 144/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.5308 - accuracy: 0.7240\n",
      "Epoch 145/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.5360 - accuracy: 0.7418\n",
      "Epoch 146/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.5371 - accuracy: 0.7140\n",
      "Epoch 147/300\n",
      "5/5 [==============================] - 0s 740us/step - loss: 0.5328 - accuracy: 0.7271\n",
      "Epoch 148/300\n",
      "5/5 [==============================] - 0s 998us/step - loss: 0.5563 - accuracy: 0.7007\n",
      "Epoch 149/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.5625 - accuracy: 0.7276\n",
      "Epoch 150/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.5285 - accuracy: 0.7424\n",
      "Epoch 151/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5046 - accuracy: 0.7680\n",
      "Epoch 152/300\n",
      "5/5 [==============================] - 0s 754us/step - loss: 0.5015 - accuracy: 0.7723\n",
      "Epoch 153/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.5297 - accuracy: 0.7189\n",
      "Epoch 154/300\n",
      "5/5 [==============================] - 0s 770us/step - loss: 0.4917 - accuracy: 0.7554\n",
      "Epoch 155/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5035 - accuracy: 0.7632\n",
      "Epoch 156/300\n",
      "5/5 [==============================] - 0s 989us/step - loss: 0.5466 - accuracy: 0.7265\n",
      "Epoch 157/300\n",
      "5/5 [==============================] - 0s 916us/step - loss: 0.5073 - accuracy: 0.7786\n",
      "Epoch 158/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.5261 - accuracy: 0.7625\n",
      "Epoch 159/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.4884 - accuracy: 0.7851\n",
      "Epoch 160/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.4760 - accuracy: 0.8163\n",
      "Epoch 161/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.4934 - accuracy: 0.7838\n",
      "Epoch 162/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.5143 - accuracy: 0.7482\n",
      "Epoch 163/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.5289 - accuracy: 0.7361\n",
      "Epoch 164/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 997us/step - loss: 0.4969 - accuracy: 0.8008\n",
      "Epoch 165/300\n",
      "5/5 [==============================] - 0s 988us/step - loss: 0.5131 - accuracy: 0.7666\n",
      "Epoch 166/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.5061 - accuracy: 0.7744\n",
      "Epoch 167/300\n",
      "5/5 [==============================] - 0s 998us/step - loss: 0.4862 - accuracy: 0.7787\n",
      "Epoch 168/300\n",
      "5/5 [==============================] - 0s 998us/step - loss: 0.4726 - accuracy: 0.8139\n",
      "Epoch 169/300\n",
      "5/5 [==============================] - 0s 746us/step - loss: 0.4820 - accuracy: 0.7992\n",
      "Epoch 170/300\n",
      "5/5 [==============================] - 0s 742us/step - loss: 0.4492 - accuracy: 0.8435\n",
      "Epoch 171/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4832 - accuracy: 0.8105\n",
      "Epoch 172/300\n",
      "5/5 [==============================] - 0s 780us/step - loss: 0.5196 - accuracy: 0.7736\n",
      "Epoch 173/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.4739 - accuracy: 0.7863\n",
      "Epoch 174/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4990 - accuracy: 0.7672\n",
      "Epoch 175/300\n",
      "5/5 [==============================] - 0s 749us/step - loss: 0.4861 - accuracy: 0.8197\n",
      "Epoch 176/300\n",
      "5/5 [==============================] - 0s 998us/step - loss: 0.4470 - accuracy: 0.8527\n",
      "Epoch 177/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4839 - accuracy: 0.8094\n",
      "Epoch 178/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4302 - accuracy: 0.8567\n",
      "Epoch 179/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4893 - accuracy: 0.8232\n",
      "Epoch 180/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.4716 - accuracy: 0.8299\n",
      "Epoch 181/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4656 - accuracy: 0.8395\n",
      "Epoch 182/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4718 - accuracy: 0.8321\n",
      "Epoch 183/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.4611 - accuracy: 0.8382\n",
      "Epoch 184/300\n",
      "5/5 [==============================] - 0s 756us/step - loss: 0.4701 - accuracy: 0.8551\n",
      "Epoch 185/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4643 - accuracy: 0.8429\n",
      "Epoch 186/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.4509 - accuracy: 0.8486\n",
      "Epoch 187/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4506 - accuracy: 0.8581\n",
      "Epoch 188/300\n",
      "5/5 [==============================] - 0s 755us/step - loss: 0.4643 - accuracy: 0.8073\n",
      "Epoch 189/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4606 - accuracy: 0.8595\n",
      "Epoch 190/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4399 - accuracy: 0.8660\n",
      "Epoch 191/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.4388 - accuracy: 0.8730\n",
      "Epoch 192/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4461 - accuracy: 0.8631\n",
      "Epoch 193/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.4220 - accuracy: 0.8670\n",
      "Epoch 194/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.4259 - accuracy: 0.8548\n",
      "Epoch 195/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4423 - accuracy: 0.8644\n",
      "Epoch 196/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4616 - accuracy: 0.8531\n",
      "Epoch 197/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.4380 - accuracy: 0.8731\n",
      "Epoch 198/300\n",
      "5/5 [==============================] - 0s 998us/step - loss: 0.4330 - accuracy: 0.8614\n",
      "Epoch 199/300\n",
      "5/5 [==============================] - 0s 919us/step - loss: 0.4307 - accuracy: 0.8670\n",
      "Epoch 200/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4291 - accuracy: 0.8940\n",
      "Epoch 201/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4256 - accuracy: 0.8867\n",
      "Epoch 202/300\n",
      "5/5 [==============================] - 0s 754us/step - loss: 0.4478 - accuracy: 0.8884\n",
      "Epoch 203/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4285 - accuracy: 0.8715\n",
      "Epoch 204/300\n",
      "5/5 [==============================] - 0s 754us/step - loss: 0.4339 - accuracy: 0.8745\n",
      "Epoch 205/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4511 - accuracy: 0.8967\n",
      "Epoch 206/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4023 - accuracy: 0.8941\n",
      "Epoch 207/300\n",
      "5/5 [==============================] - 0s 998us/step - loss: 0.4361 - accuracy: 0.8624\n",
      "Epoch 208/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4217 - accuracy: 0.8989\n",
      "Epoch 209/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4159 - accuracy: 0.8954\n",
      "Epoch 210/300\n",
      "5/5 [==============================] - 0s 756us/step - loss: 0.4344 - accuracy: 0.8807\n",
      "Epoch 211/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4242 - accuracy: 0.8863\n",
      "Epoch 212/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4023 - accuracy: 0.9024\n",
      "Epoch 213/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4149 - accuracy: 0.8729\n",
      "Epoch 214/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4245 - accuracy: 0.8907\n",
      "Epoch 215/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4003 - accuracy: 0.9072\n",
      "Epoch 216/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4174 - accuracy: 0.8699\n",
      "Epoch 217/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.3999 - accuracy: 0.9159\n",
      "Epoch 218/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.4066 - accuracy: 0.9211\n",
      "Epoch 219/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4237 - accuracy: 0.9199\n",
      "Epoch 220/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4053 - accuracy: 0.9077\n",
      "Epoch 221/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.4130 - accuracy: 0.9056\n",
      "Epoch 222/300\n",
      "5/5 [==============================] - 0s 992us/step - loss: 0.4128 - accuracy: 0.9169\n",
      "Epoch 223/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.4064 - accuracy: 0.9199\n",
      "Epoch 224/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4045 - accuracy: 0.9278\n",
      "Epoch 225/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.3931 - accuracy: 0.9281\n",
      "Epoch 226/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.3903 - accuracy: 0.8973\n",
      "Epoch 227/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3704 - accuracy: 0.9434\n",
      "Epoch 228/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.3978 - accuracy: 0.9143\n",
      "Epoch 229/300\n",
      "5/5 [==============================] - 0s 998us/step - loss: 0.4100 - accuracy: 0.9147\n",
      "Epoch 230/300\n",
      "5/5 [==============================] - 0s 998us/step - loss: 0.3932 - accuracy: 0.9039\n",
      "Epoch 231/300\n",
      "5/5 [==============================] - 0s 631us/step - loss: 0.3906 - accuracy: 0.9304\n",
      "Epoch 232/300\n",
      "5/5 [==============================] - 0s 998us/step - loss: 0.3764 - accuracy: 0.9326\n",
      "Epoch 233/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.3755 - accuracy: 0.9565\n",
      "Epoch 234/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.3929 - accuracy: 0.9201\n",
      "Epoch 235/300\n",
      "5/5 [==============================] - 0s 741us/step - loss: 0.3998 - accuracy: 0.9249\n",
      "Epoch 236/300\n",
      "5/5 [==============================] - 0s 996us/step - loss: 0.3598 - accuracy: 0.9570\n",
      "Epoch 237/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.3942 - accuracy: 0.9153\n",
      "Epoch 238/300\n",
      "5/5 [==============================] - 0s 999us/step - loss: 0.3938 - accuracy: 0.9284\n",
      "Epoch 239/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3910 - accuracy: 0.9258\n",
      "Epoch 240/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.3925 - accuracy: 0.9501\n",
      "Epoch 241/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.3651 - accuracy: 0.9518\n",
      "Epoch 242/300\n",
      "5/5 [==============================] - 0s 756us/step - loss: 0.3785 - accuracy: 0.9566\n",
      "Epoch 243/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.3755 - accuracy: 0.9636\n",
      "Epoch 244/300\n",
      "5/5 [==============================] - 0s 998us/step - loss: 0.3558 - accuracy: 0.9614\n",
      "Epoch 245/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 499us/step - loss: 0.3832 - accuracy: 0.9419\n",
      "Epoch 246/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.3810 - accuracy: 0.9319\n",
      "Epoch 247/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.3815 - accuracy: 0.9623\n",
      "Epoch 248/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.3572 - accuracy: 0.9419\n",
      "Epoch 249/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.3667 - accuracy: 0.9193\n",
      "Epoch 250/300\n",
      "5/5 [==============================] - 0s 863us/step - loss: 0.3936 - accuracy: 0.9492\n",
      "Epoch 251/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.3687 - accuracy: 0.9466\n",
      "Epoch 252/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.3723 - accuracy: 0.9384\n",
      "Epoch 253/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.3756 - accuracy: 0.9449\n",
      "Epoch 254/300\n",
      "5/5 [==============================] - 0s 996us/step - loss: 0.3515 - accuracy: 0.9601\n",
      "Epoch 255/300\n",
      "5/5 [==============================] - 0s 968us/step - loss: 0.3610 - accuracy: 0.9358\n",
      "Epoch 256/300\n",
      "5/5 [==============================] - 0s 998us/step - loss: 0.3461 - accuracy: 0.9475\n",
      "Epoch 257/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3662 - accuracy: 0.9484\n",
      "Epoch 258/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.3350 - accuracy: 0.9557\n",
      "Epoch 259/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.3358 - accuracy: 0.9419\n",
      "Epoch 260/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.3460 - accuracy: 0.9492\n",
      "Epoch 261/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.3380 - accuracy: 0.9636\n",
      "Epoch 262/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3474 - accuracy: 0.9336\n",
      "Epoch 263/300\n",
      "5/5 [==============================] - 0s 817us/step - loss: 0.3718 - accuracy: 0.9223\n",
      "Epoch 264/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.3311 - accuracy: 0.9522\n",
      "Epoch 265/300\n",
      "5/5 [==============================] - 0s 998us/step - loss: 0.3577 - accuracy: 0.9414\n",
      "Epoch 266/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.3745 - accuracy: 0.9205\n",
      "Epoch 267/300\n",
      "5/5 [==============================] - 0s 998us/step - loss: 0.3440 - accuracy: 0.9375\n",
      "Epoch 268/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.3487 - accuracy: 0.9396\n",
      "Epoch 269/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.3237 - accuracy: 0.9487\n",
      "Epoch 270/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.3236 - accuracy: 0.9457\n",
      "Epoch 271/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3448 - accuracy: 0.9301\n",
      "Epoch 272/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3399 - accuracy: 0.9388\n",
      "Epoch 273/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.3583 - accuracy: 0.9231\n",
      "Epoch 274/300\n",
      "5/5 [==============================] - 0s 998us/step - loss: 0.3368 - accuracy: 0.9223\n",
      "Epoch 275/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.3043 - accuracy: 0.9448\n",
      "Epoch 276/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3314 - accuracy: 0.9284\n",
      "Epoch 277/300\n",
      "5/5 [==============================] - 0s 747us/step - loss: 0.3628 - accuracy: 0.9214\n",
      "Epoch 278/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.3442 - accuracy: 0.9166\n",
      "Epoch 279/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.3370 - accuracy: 0.9396\n",
      "Epoch 280/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.3154 - accuracy: 0.9427\n",
      "Epoch 281/300\n",
      "5/5 [==============================] - 0s 629us/step - loss: 0.3043 - accuracy: 0.9596\n",
      "Epoch 282/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.3142 - accuracy: 0.9301\n",
      "Epoch 283/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.3245 - accuracy: 0.9244\n",
      "Epoch 284/300\n",
      "5/5 [==============================] - 0s 989us/step - loss: 0.3254 - accuracy: 0.9231\n",
      "Epoch 285/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3440 - accuracy: 0.9292\n",
      "Epoch 286/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.3176 - accuracy: 0.9344\n",
      "Epoch 287/300\n",
      "5/5 [==============================] - 0s 760us/step - loss: 0.3071 - accuracy: 0.9318\n",
      "Epoch 288/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3188 - accuracy: 0.9331\n",
      "Epoch 289/300\n",
      "5/5 [==============================] - 0s 903us/step - loss: 0.3262 - accuracy: 0.9270\n",
      "Epoch 290/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.3163 - accuracy: 0.9297\n",
      "Epoch 291/300\n",
      "5/5 [==============================] - 0s 995us/step - loss: 0.3076 - accuracy: 0.9514\n",
      "Epoch 292/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.3158 - accuracy: 0.9288\n",
      "Epoch 293/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.3051 - accuracy: 0.9375\n",
      "Epoch 294/300\n",
      "5/5 [==============================] - 0s 925us/step - loss: 0.3053 - accuracy: 0.9483\n",
      "Epoch 295/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.2860 - accuracy: 0.9401\n",
      "Epoch 296/300\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3145 - accuracy: 0.9445\n",
      "Epoch 297/300\n",
      "5/5 [==============================] - 0s 748us/step - loss: 0.2980 - accuracy: 0.9510\n",
      "Epoch 298/300\n",
      "5/5 [==============================] - 0s 988us/step - loss: 0.3074 - accuracy: 0.9467\n",
      "Epoch 299/300\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.2897 - accuracy: 0.9549\n",
      "Epoch 300/300\n",
      "5/5 [==============================] - 0s 781us/step - loss: 0.3004 - accuracy: 0.9606\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e70e06dbc8>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(scaled_X,y,epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"final_iris_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['iris_scaler.pkl']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(scaler,'iris_scaler.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting a Single New Flower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_model = load_model(\"final_iris_model.h5\")\n",
    "flower_scaler = joblib.load(\"iris_scaler.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_example = {'sepal_length':5.1,\n",
    "                 'sepal_width':3.5,\n",
    "                 'petal_length':1.4,\n",
    "                 'petal_width':0.2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['sepal_length', 'sepal_width', 'petal_length', 'petal_width'])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flower_example.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_prediction(model,scaler,sample_json):\n",
    "    \n",
    "    # For larger data features, you should probably write a for loop\n",
    "    # That builds out this array for you\n",
    "    \n",
    "    s_len = sample_json['sepal_length']\n",
    "    s_wid = sample_json['sepal_width']\n",
    "    p_len = sample_json['petal_length']\n",
    "    p_wid = sample_json['petal_width']\n",
    "    \n",
    "    flower = [[s_len,s_wid,p_len,p_wid]]\n",
    "    \n",
    "    flower = scaler.transform(flower)\n",
    "    \n",
    "    classes = np.array(['setosa', 'versicolor', 'virginica'])\n",
    "    \n",
    "    class_ind = model.predict_classes(flower)\n",
    "    \n",
    "    return classes[class_ind][0]\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\deeplearning\\env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'setosa'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_prediction(flower_model,flower_scaler,flower_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CODE FOR DEPLOYMENT:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import joblib\n",
    "\n",
    "\n",
    "flower_model = load_model(\"final_iris_model.h5\")\n",
    "flower_scaler = joblib.load(\"iris_scaler.pkl\")\n",
    "\n",
    "\n",
    "def return_prediction(model,scaler,sample_json):\n",
    "    \n",
    "    # For larger data features, you should probably write a for loop\n",
    "    # That builds out this array for you\n",
    "    \n",
    "    s_len = sample_json['sepal_length']\n",
    "    s_wid = sample_json['sepal_width']\n",
    "    p_len = sample_json['petal_length']\n",
    "    p_wid = sample_json['petal_width']\n",
    "    \n",
    "    flower = [[s_len,s_wid,p_len,p_wid]]\n",
    "    \n",
    "    flower = scaler.transform(flower)\n",
    "    \n",
    "    classes = np.array(['setosa', 'versicolor', 'virginica'])\n",
    "    \n",
    "    class_ind = model.predict_classes(flower)\n",
    "    \n",
    "    return classes[class_ind][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_example = {\n",
    "\"sepal_length\":5.1,\n",
    "\"sepal_width\":3.5,\n",
    "\"petal_length\":1.4,\n",
    "\"petal_width\":0.2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = requests.post(\"http://127.0.0.1:5000/api/flower\",json=flower_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"setosa\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(results.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
